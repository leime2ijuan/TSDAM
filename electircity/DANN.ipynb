{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af539430-6ab9-4036-8337-cb1f53316dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 基于迁移学习的两阶段方法\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from dataloader import create_all_dataloaders, create_category_dataloaders, create_transfer_dataloaders,ChronosDataset\n",
    "from calculate import calculate_metrics, print_metrics_table,calculate_uncertainty_metrics\n",
    "# 设置随机种子以确保可重复性\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 检查CUDA是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2450957-2f0e-4f86-8b5e-700cce6b20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_uncertainty(model, inputs, category, domain_idx=None, mc_samples=100, device='cuda'):\n",
    "    \"\"\"\n",
    "    使用MC Dropout进行不确定性估计 - 适配DANN模型\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    category = category.to(device)\n",
    "    model.train()  # 开启dropout以进行随机采样\n",
    "    \n",
    "    predictions = []\n",
    "    for _ in range(mc_samples):\n",
    "        # 对于DANN模型，忽略domain_idx参数\n",
    "        outputs = model(inputs, category)\n",
    "        \n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]  # 如果模型返回元组，取第一个元素\n",
    "        \n",
    "        predictions.append(outputs.detach())\n",
    "    \n",
    "    # 将预测堆叠为形状[mc_samples, batch, buildings, forecasts]\n",
    "    try:\n",
    "        stacked_preds = torch.stack(predictions, dim=0)\n",
    "        \n",
    "        # 计算平均值和标准差\n",
    "        mean_pred = torch.mean(stacked_preds, dim=0)\n",
    "        std_pred = torch.std(stacked_preds, dim=0)\n",
    "        \n",
    "        # 计算95%置信区间\n",
    "        lower_bound = mean_pred - 1.96 * std_pred\n",
    "        upper_bound = mean_pred + 1.96 * std_pred\n",
    "        \n",
    "        # 确保边界在有效范围内\n",
    "        lower_bound = torch.clamp(lower_bound, 0, 1)\n",
    "        upper_bound = torch.clamp(upper_bound, 0, 1)\n",
    "        \n",
    "        # 转换为CPU NumPy数组\n",
    "        return (mean_pred.cpu().numpy(),\n",
    "                lower_bound.cpu().numpy(),\n",
    "                upper_bound.cpu().numpy(),\n",
    "                std_pred.cpu().numpy())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"处理MC采样结果时出错: {str(e)}\")\n",
    "        # 如果堆叠或其他操作失败，使用第一个样本作为预测\n",
    "        try:\n",
    "            mean_pred = predictions[0].cpu().numpy()\n",
    "            std_pred = np.ones_like(mean_pred) * 0.1\n",
    "            lower_bound = np.maximum(mean_pred - 1.96 * std_pred, 0)\n",
    "            upper_bound = np.minimum(mean_pred + 1.96 * std_pred, 1)\n",
    "            return mean_pred, lower_bound, upper_bound, std_pred\n",
    "        except:\n",
    "            # 最后的后备方案：返回零数组\n",
    "            shape = list(inputs.shape)\n",
    "            if len(shape) >= 3:\n",
    "                shape[-1] = 1\n",
    "            zeros = np.zeros(shape)\n",
    "            return zeros, zeros, zeros, zeros\n",
    "def calculate_transfer_metrics(source_features, target_features, source_outputs=None, target_outputs=None, baseline_predictions=None, targets=None):\n",
    "    \"\"\"\n",
    "    计算迁移学习的综合评估指标\n",
    "    \n",
    "    Args:\n",
    "        source_features: 源域特征 [batch_size, feature_dim]\n",
    "        target_features: 目标域特征 [batch_size, feature_dim]\n",
    "        source_outputs: 源域模型输出（可选）\n",
    "        target_outputs: 目标域模型输出（可选）\n",
    "        baseline_predictions: 基线模型预测（可选）\n",
    "        targets: 真实目标值（可选，用于计算负迁移）\n",
    "    \"\"\"\n",
    "    import traceback  # 导入traceback以便打印详细错误信息\n",
    "    \n",
    "    # 处理3D特征 - 将3D特征转换为2D\n",
    "    if len(source_features.shape) == 3:  # [batch, seq_len, feature_dim]\n",
    "        logging.info(f\"检测到3D特征，进行展平: source_features.shape={source_features.shape}\")\n",
    "        # 方法2：平均所有时间步\n",
    "        source_features = source_features.mean(dim=1)  # [batch, feature_dim]\n",
    "        target_features = target_features.mean(dim=1)  # [batch, feature_dim]\n",
    "        \n",
    "        logging.info(f\"展平后: source_features.shape={source_features.shape}, target_features.shape={target_features.shape}\")\n",
    "    \n",
    "    # 确保特征维度匹配\n",
    "    if source_features.size(1) != target_features.size(1):\n",
    "        logging.warning(f\"特征维度不匹配: source_features.shape={source_features.shape}, target_features.shape={target_features.shape}\")\n",
    "        return {\n",
    "            'a_distance': 'N/A',\n",
    "            'feature_alignment': 'N/A',\n",
    "            'mmd': 'N/A',\n",
    "            'sample_efficiency': None,\n",
    "            'CC': 'N/A'  # 添加CC字段\n",
    "        }\n",
    "    \n",
    "    # 检查特征数量是否过大，可能导致内存问题\n",
    "    max_samples = 5000\n",
    "    if source_features.size(0) > max_samples or target_features.size(0) > max_samples:\n",
    "        logging.warning(f\"特征数量过大，进行采样: source_features.shape={source_features.shape}, target_features.shape={target_features.shape}\")\n",
    "        \n",
    "        if source_features.size(0) > max_samples:\n",
    "            indices = torch.randperm(source_features.size(0))[:max_samples]\n",
    "            source_features = source_features[indices]\n",
    "        \n",
    "        if target_features.size(0) > max_samples:\n",
    "            indices = torch.randperm(target_features.size(0))[:max_samples]\n",
    "            target_features = target_features[indices]\n",
    "        \n",
    "        logging.info(f\"采样后: source_features.shape={source_features.shape}, target_features.shape={target_features.shape}\")\n",
    "    \n",
    "    def calculate_mmd(x, y):\n",
    "        \"\"\"计算最大平均差异(MMD)\"\"\"\n",
    "        try:\n",
    "            x_kernel = torch.mm(x, x.t())\n",
    "            y_kernel = torch.mm(y, y.t())\n",
    "            xy_kernel = torch.mm(x, y.t())\n",
    "            return x_kernel.mean() + y_kernel.mean() - 2 * xy_kernel.mean()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"计算MMD时出错: {str(e)}\")\n",
    "            return float('nan')\n",
    "    \n",
    "    def calculate_a_distance(source_features, target_features):\n",
    "        \"\"\"计算A-distance\"\"\"\n",
    "        try:\n",
    "            domain_classifier = nn.Sequential(\n",
    "                nn.Linear(source_features.size(1), 50),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, 1)\n",
    "            ).to(source_features.device)\n",
    "            \n",
    "            source_domain_labels = torch.ones(source_features.size(0), 1).to(source_features.device)\n",
    "            target_domain_labels = torch.zeros(target_features.size(0), 1).to(source_features.device)\n",
    "            \n",
    "            features = torch.cat([source_features, target_features], dim=0)\n",
    "            labels = torch.cat([source_domain_labels, target_domain_labels], dim=0)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(domain_classifier.parameters())\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            \n",
    "            for _ in range(100):\n",
    "                optimizer.zero_grad()\n",
    "                preds = domain_classifier(features)\n",
    "                loss = criterion(preds, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # 确保使用浮点数计算均值\n",
    "                preds = torch.sigmoid(domain_classifier(features))\n",
    "                predicted_labels = (preds > 0.5).float()\n",
    "                error = (predicted_labels != labels).float().mean()\n",
    "            \n",
    "            return 2 * (1 - 2 * error)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"计算A-distance时出错: {str(e)}\")\n",
    "            traceback.print_exc()  # 打印详细错误信息\n",
    "            return float('nan')\n",
    "    \n",
    "    def calculate_feature_alignment(source_features, target_features):\n",
    "        \"\"\"计算特征对齐质量\"\"\"\n",
    "        try:\n",
    "            source_norm = F.normalize(source_features, p=2, dim=1)\n",
    "            target_norm = F.normalize(target_features, p=2, dim=1)\n",
    "            similarity = torch.mm(source_norm, target_norm.t())\n",
    "            return similarity.mean()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"计算特征对齐质量时出错: {str(e)}\")\n",
    "            return float('nan')\n",
    "    \n",
    "    # 添加计算相关系数(CC)的函数\n",
    "    def calculate_correlation_coefficient(predictions, targets):\n",
    "        \"\"\"计算相关系数(CC)\"\"\"\n",
    "        try:\n",
    "            # 确保输入是numpy数组\n",
    "            if isinstance(predictions, torch.Tensor):\n",
    "                predictions = predictions.detach().cpu().numpy()\n",
    "            if isinstance(targets, torch.Tensor):\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "            \n",
    "            # 展平数组\n",
    "            predictions = np.array(predictions).flatten()\n",
    "            targets = np.array(targets).flatten()\n",
    "            \n",
    "            # 确保长度相同\n",
    "            min_length = min(len(predictions), len(targets))\n",
    "            predictions = predictions[:min_length]\n",
    "            targets = targets[:min_length]\n",
    "            \n",
    "            # 计算相关系数\n",
    "            cc = np.corrcoef(predictions, targets)[0, 1]\n",
    "            return cc\n",
    "        except Exception as e:\n",
    "            logging.error(f\"计算相关系数时出错: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return float('nan')\n",
    "\n",
    "    try:\n",
    "        metrics = {\n",
    "            'a_distance': calculate_a_distance(source_features, target_features),\n",
    "            'feature_alignment': calculate_feature_alignment(source_features, target_features),\n",
    "            'mmd': calculate_mmd(source_features, target_features)\n",
    "        }\n",
    "        \n",
    "        # 如果提供了目标域输出和真实目标值，计算相关系数\n",
    "        if target_outputs is not None and targets is not None:\n",
    "            metrics['CC'] = calculate_correlation_coefficient(target_outputs, targets)\n",
    "        else:\n",
    "            metrics['CC'] = float('nan')  # 如果没有提供必要数据，设置为NaN\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"计算迁移学习指标时出错: {str(e)}\")\n",
    "        traceback.print_exc()  # 打印详细错误信息\n",
    "        return {\n",
    "            'a_distance': 'N/A',\n",
    "            'feature_alignment': 'N/A',\n",
    "            'mmd': 'N/A',\n",
    "            'CC': 'N/A'  # 添加CC字段\n",
    "        }\n",
    "    \n",
    "    # 如果提供了输出、基线预测和目标值，检测负迁移\n",
    "    if target_outputs is not None and baseline_predictions is not None and targets is not None:\n",
    "        try:\n",
    "            # 确保所有输入都是张量并且形状匹配\n",
    "            # 首先转换为numpy数组以便统一处理\n",
    "            if isinstance(target_outputs, torch.Tensor):\n",
    "                target_outputs = target_outputs.detach().cpu().numpy()\n",
    "            if isinstance(baseline_predictions, torch.Tensor):\n",
    "                baseline_predictions = baseline_predictions.detach().cpu().numpy()\n",
    "            if isinstance(targets, torch.Tensor):\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "            \n",
    "            # 确保都是一维数组\n",
    "            target_outputs = np.array(target_outputs).flatten()\n",
    "            baseline_predictions = np.array(baseline_predictions).flatten()\n",
    "            targets = np.array(targets).flatten()\n",
    "            \n",
    "            # 确保所有数组长度相同\n",
    "            min_length = min(len(target_outputs), len(baseline_predictions), len(targets))\n",
    "            target_outputs = target_outputs[:min_length]\n",
    "            baseline_predictions = baseline_predictions[:min_length]\n",
    "            targets = targets[:min_length]\n",
    "            \n",
    "            # 计算MSE损失\n",
    "            target_loss = np.mean((target_outputs - targets) ** 2)\n",
    "            baseline_loss = np.mean((baseline_predictions - targets) ** 2)\n",
    "            \n",
    "            # 打印调试信息\n",
    "            logging.debug(f\"target_loss: {target_loss}, type: {type(target_loss)}\")\n",
    "            logging.debug(f\"baseline_loss: {baseline_loss}, type: {type(baseline_loss)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"计算负迁移指标时出错: {str(e)}\")\n",
    "            traceback.print_exc()  # 打印详细错误信息\n",
    "    \n",
    "    return metrics\n",
    "def evaluate_model(model, test_loader, model_name=\"Model\", baseline_model=None, device='cuda', domain_idx=None):\n",
    "    \"\"\"\n",
    "    评估模型在测试集上的性能 - 适配DANN模型\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_lower_bounds = []\n",
    "    all_upper_bounds = []\n",
    "    all_uncertainties = []\n",
    "    # 用于迁移学习评估的特征收集\n",
    "    source_features = []\n",
    "    target_features = []\n",
    "    source_outputs = []\n",
    "    target_outputs = []\n",
    "    \n",
    "    # 计算标准预测和不确定性估计\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, _, category_onehot in test_loader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            category_onehot = category_onehot.float().to(device)\n",
    "            \n",
    "            try:\n",
    "                # 获取特征表示（用于迁移学习评估）\n",
    "                if isinstance(model, DANN):\n",
    "                    try:\n",
    "                        # 对于DANN模型，直接获取特征\n",
    "                        features = model.get_features(inputs)\n",
    "                        # 由于DANN没有显式的域区分，我们可以将相同的特征用于源域和目标域\n",
    "                        source_features.append(features)\n",
    "                        target_features.append(features)\n",
    "                    except Exception as e:\n",
    "                        print(f\"提取DANN特征时出错: {str(e)}\")\n",
    "                \n",
    "                # 使用MC Dropout估计不确定性\n",
    "                mean_pred, lower_bound, upper_bound, uncertainty = predict_with_uncertainty(\n",
    "                    model=model, \n",
    "                    inputs=inputs, \n",
    "                    category=category_onehot,\n",
    "                    device=device, \n",
    "                    mc_samples=50\n",
    "                )\n",
    "                \n",
    "                # 收集预测结果\n",
    "                if isinstance(mean_pred, torch.Tensor):\n",
    "                    mean_pred = mean_pred.cpu().numpy()\n",
    "                \n",
    "                # 尝试收集源域和目标域的输出\n",
    "                try:\n",
    "                    if isinstance(model, DANN):\n",
    "                        # 对于DANN模型，我们可以将相同的预测用于源域和目标域\n",
    "                        source_outputs.append(mean_pred)\n",
    "                        target_outputs.append(mean_pred)\n",
    "                except Exception as e:\n",
    "                    print(f\"收集DANN输出时出错: {str(e)}\")\n",
    "                \n",
    "                # 收集预测、目标和不确定性信息\n",
    "                all_predictions.append(mean_pred)\n",
    "                all_targets.append(targets.cpu().numpy())\n",
    "                all_lower_bounds.append(lower_bound)\n",
    "                all_upper_bounds.append(upper_bound)\n",
    "                all_uncertainties.append(uncertainty)\n",
    "            except Exception as e:\n",
    "                print(f\"批次处理过程中发生错误: {str(e)}\")\n",
    "                print(f\"跳过此批次\")\n",
    "                continue\n",
    "    \n",
    "    \n",
    "    # 检查是否有有效预测\n",
    "    if not all_predictions:\n",
    "        print(\"警告: 没有收集到任何有效预测，无法评估模型\")\n",
    "        return {\"Model\": model_name, \"Error\": \"无有效预测\"}\n",
    "    \n",
    "    # 合并所有批次的预测和目标\n",
    "    try:\n",
    "        all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "        all_targets = np.concatenate(all_targets, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"合并预测和目标时出错: {str(e)}\")\n",
    "        return {\"Model\": model_name, \"Error\": f\"合并数据失败: {str(e)}\"}\n",
    "    \n",
    "    # 检查不确定性相关的列表是否为空或合并是否成功\n",
    "    if not all_lower_bounds or not all_upper_bounds or not all_uncertainties:\n",
    "        print(\"警告: 不确定性估计列表为空，使用默认值\")\n",
    "        # 创建默认的不确定性估计\n",
    "        all_lower_bounds = all_predictions * 0.9  # 简单地使用预测值的90%作为下界\n",
    "        all_upper_bounds = all_predictions * 1.1  # 预测值的110%作为上界\n",
    "        all_uncertainties = np.ones_like(all_predictions) * 0.1  # 默认不确定性为0.1\n",
    "    else:\n",
    "        # 合并所有批次的不确定性估计\n",
    "        try:\n",
    "            all_lower_bounds = np.concatenate(all_lower_bounds, axis=0)\n",
    "            all_upper_bounds = np.concatenate(all_upper_bounds, axis=0)\n",
    "            all_uncertainties = np.concatenate(all_uncertainties, axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"合并不确定性估计时出错: {str(e)}\")\n",
    "            # 如果合并失败，使用默认值\n",
    "            all_lower_bounds = all_predictions * 0.9\n",
    "            all_upper_bounds = all_predictions * 1.1\n",
    "            all_uncertainties = np.ones_like(all_predictions) * 0.1\n",
    "    \n",
    "    # 展平数组以便计算指标\n",
    "    # 确保所有数组具有相同的形状\n",
    "    all_predictions_flat = all_predictions.reshape(-1)\n",
    "    all_targets_flat = all_targets.reshape(-1)\n",
    "    \n",
    "    # 确保不确定性相关的数组与预测和目标具有相同形状\n",
    "    # 如果形状不同，可能需要广播或重采样\n",
    "    if all_lower_bounds.size != all_predictions_flat.size:\n",
    "        print(f\"警告: 下界形状 {all_lower_bounds.shape} 与预测形状 {all_predictions.shape} 不一致\")\n",
    "        # 重塑或截断\n",
    "        all_lower_bounds = all_lower_bounds.reshape(-1)[:all_predictions_flat.size]\n",
    "        all_upper_bounds = all_upper_bounds.reshape(-1)[:all_predictions_flat.size]\n",
    "        all_uncertainties = all_uncertainties.reshape(-1)[:all_predictions_flat.size]\n",
    "    else:\n",
    "        all_lower_bounds = all_lower_bounds.reshape(-1)\n",
    "        all_upper_bounds = all_upper_bounds.reshape(-1)\n",
    "        all_uncertainties = all_uncertainties.reshape(-1)\n",
    "    \n",
    "    # 打印形状信息用于调试\n",
    "    print(f\"形状信息:\")\n",
    "    print(f\"预测: {all_predictions_flat.shape}\")\n",
    "    print(f\"目标: {all_targets_flat.shape}\")\n",
    "    print(f\"下界: {all_lower_bounds.shape}\")\n",
    "    print(f\"上界: {all_upper_bounds.shape}\")\n",
    "    print(f\"不确定性: {all_uncertainties.shape}\")\n",
    "    \n",
    "    # 如果提供了基线模型，获取基线预测\n",
    "    baseline_predictions = None\n",
    "    if baseline_model is not None:\n",
    "        baseline_model.eval()\n",
    "        all_baseline_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, _, _, category_onehot in test_loader:\n",
    "                try:\n",
    "                    inputs = inputs.float().to(device)\n",
    "                    category_onehot = category_onehot.float().to(device)\n",
    "                    \n",
    "                    # 根据基线模型类型获取预测\n",
    "                    if hasattr(baseline_model, 'predict'):\n",
    "                        # 如果基线模型有predict方法\n",
    "                        baseline_pred = baseline_model.predict(inputs)\n",
    "                    else:\n",
    "                        # 尝试直接获取预测值\n",
    "                        baseline_pred = baseline_model(inputs, category_onehot)\n",
    "                        # 处理返回元组的情况\n",
    "                        if isinstance(baseline_pred, tuple):\n",
    "                            baseline_pred = baseline_pred[0]\n",
    "                    \n",
    "                    # 转换为NumPy数组\n",
    "                    if isinstance(baseline_pred, torch.Tensor):\n",
    "                        baseline_pred = baseline_pred.cpu().numpy()\n",
    "                    \n",
    "                    all_baseline_predictions.append(baseline_pred)\n",
    "                except Exception as e:\n",
    "                    print(f\"获取基线预测时出错: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        # 合并所有批次的基线预测\n",
    "        if all_baseline_predictions:\n",
    "            try:\n",
    "                baseline_predictions = np.concatenate(all_baseline_predictions, axis=0).reshape(-1)\n",
    "                \n",
    "                # 确保基线预测具有相同的大小\n",
    "                if baseline_predictions.size != all_predictions_flat.size:\n",
    "                    print(f\"警告: 基线预测形状 {baseline_predictions.shape} 与预测形状 {all_predictions_flat.shape} 不一致\")\n",
    "                    baseline_predictions = baseline_predictions[:all_predictions_flat.size]\n",
    "            except Exception as e:\n",
    "                print(f\"处理基线预测时出错: {str(e)}\")\n",
    "                baseline_predictions = None\n",
    "    \n",
    "    # 改进的MAPE计算函数\n",
    "    def calculate_improved_mape(y_true, y_pred, epsilon=0.01):\n",
    "        \"\"\"\n",
    "        计算改进的MAPE，忽略接近零的值\n",
    "        \n",
    "        参数:\n",
    "        - y_true: 真实值数组\n",
    "        - y_pred: 预测值数组\n",
    "        - epsilon: 阈值，避免除以接近零的值，对于0-1区间的数据，0.01是合理的\n",
    "        \n",
    "        返回:\n",
    "        - MAPE值(百分比)\n",
    "        \"\"\"\n",
    "        mask = np.abs(y_true) > epsilon\n",
    "        if not np.any(mask):\n",
    "            return float('nan')  # 如果没有有效值，返回NaN\n",
    "        \n",
    "        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    \n",
    "    # 计算评估指标，包含基线预测和置信区间\n",
    "    try:\n",
    "        metrics = calculate_metrics(\n",
    "            predictions=all_predictions_flat, \n",
    "            real_values=all_targets_flat, \n",
    "            model_name=model_name, \n",
    "            baseline_predictions=baseline_predictions,\n",
    "            lower_bounds=all_lower_bounds,\n",
    "            upper_bounds=all_upper_bounds,\n",
    "            confidence=0.95\n",
    "        )\n",
    "        \n",
    "        # 添加平均不确定性\n",
    "        metrics['avg_uncertainty'] = np.mean(all_uncertainties)\n",
    "        \n",
    "        # 使用改进的MAPE计算\n",
    "        try:\n",
    "            metrics['MAPE'] = calculate_improved_mape(all_targets_flat, all_predictions_flat, epsilon=0.01)\n",
    "        except Exception as e:\n",
    "            print(f\"计算改进MAPE时出错: {str(e)}\")\n",
    "            # 保留原始MAPE或设置为NaN\n",
    "            if 'MAPE' not in metrics:\n",
    "                metrics['MAPE'] = float('nan')\n",
    "    \n",
    "        # 计算迁移学习指标 - 仅当所有必要的列表都非空时\n",
    "        if (source_features and target_features and \n",
    "            source_outputs and target_outputs):\n",
    "            try:\n",
    "                # 处理特征数据\n",
    "                source_features = torch.cat(source_features, dim=0).cpu()\n",
    "                target_features = torch.cat(target_features, dim=0).cpu()\n",
    "                source_outputs = np.concatenate(source_outputs, axis=0)\n",
    "                target_outputs = np.concatenate(target_outputs, axis=0)\n",
    "    \n",
    "                # 计算迁移学习相关指标\n",
    "                transfer_metrics = calculate_transfer_metrics(\n",
    "                    source_features=source_features,\n",
    "                    target_features=target_features,\n",
    "                    source_outputs=source_outputs,\n",
    "                    target_outputs=target_outputs,\n",
    "                    baseline_predictions=baseline_predictions,\n",
    "                    targets=all_targets_flat\n",
    "                )\n",
    "                # 更新指标字典\n",
    "                metrics.update(transfer_metrics)\n",
    "            except Exception as e:\n",
    "                print(f\"计算迁移学习指标时出错: {str(e)}\")\n",
    "                # 不要让这个错误影响整个评估流程\n",
    "        else:\n",
    "            print(\"警告: 迁移学习特征或输出列表为空，跳过迁移学习指标计算\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"计算指标时出错: {str(e)}\")\n",
    "        # 创建一个基本的指标集作为回退\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        rmse = np.sqrt(mean_squared_error(all_targets_flat, all_predictions_flat))\n",
    "        r2 = r2_score(all_targets_flat, all_predictions_flat)\n",
    "        \n",
    "        metrics = {\n",
    "            'Model': model_name,\n",
    "            'RMSD': rmse,\n",
    "            'R2': r2,\n",
    "            'avg_uncertainty': np.mean(all_uncertainties)\n",
    "        }\n",
    "        \n",
    "        # 尝试计算改进的MAPE\n",
    "        try:\n",
    "            metrics['MAPE'] = calculate_improved_mape(all_targets_flat, all_predictions_flat, epsilon=0.01)\n",
    "        except Exception as e:\n",
    "            print(f\"计算改进MAPE时出错: {str(e)}\")\n",
    "            metrics['MAPE'] = float('nan')\n",
    "    \n",
    "    # 打印详细的评估报告\n",
    "    print(f\"\\n{model_name} 评估报告:\")\n",
    "    print(f\"RMSD: {metrics.get('RMSD', 'N/A')}\")\n",
    "    print(f\"MAPE: {metrics.get('MAPE', 'N/A')}%\")\n",
    "    print(f\"R²: {metrics.get('R2', 'N/A')}\")\n",
    "    print(f\"KL散度: {metrics.get('KL_divergence', 'N/A')}\")\n",
    "    \n",
    "    # 打印迁移学习指标 - 安全处理格式化\n",
    "    if any(key in metrics for key in ['a_distance', 'feature_alignment', 'mmd']):\n",
    "        print(\"\\n迁移学习评估:\")\n",
    "        \n",
    "        # 安全处理a_distance\n",
    "        a_distance = metrics.get('a_distance', 'N/A')\n",
    "        if isinstance(a_distance, (int, float)) and not (isinstance(a_distance, float) and np.isnan(a_distance)):\n",
    "            print(f\"域间距离 (A-distance): {a_distance:.4f}\")\n",
    "        else:\n",
    "            print(f\"域间距离 (A-distance): {a_distance}\")\n",
    "        \n",
    "        # 安全处理feature_alignment\n",
    "        feature_alignment = metrics.get('feature_alignment', 'N/A')\n",
    "        if isinstance(feature_alignment, (int, float)) and not (isinstance(feature_alignment, float) and np.isnan(feature_alignment)):\n",
    "            print(f\"特征对齐质量: {feature_alignment:.4f}\")\n",
    "        else:\n",
    "            print(f\"特征对齐质量: {feature_alignment}\")\n",
    "        \n",
    "        # 安全处理mmd\n",
    "        mmd = metrics.get('mmd', 'N/A')\n",
    "        if isinstance(mmd, (int, float)) and not (isinstance(mmd, float) and np.isnan(mmd)):\n",
    "            print(f\"MMD: {mmd:.4f}\")\n",
    "        else:\n",
    "            print(f\"MMD: {mmd}\")\n",
    "        \n",
    "  \n",
    "    # 打印不确定性评估指标 - 安全处理\n",
    "    if 'PICP' in metrics:\n",
    "        print(f\"\\n不确定性评估:\")\n",
    "        \n",
    "        picp = metrics.get('PICP', 'N/A')\n",
    "        if isinstance(picp, (int, float)) and not (isinstance(picp, float) and np.isnan(picp)):\n",
    "            print(f\"预测区间覆盖率(PICP): {picp:.2f}% (目标95%)\")\n",
    "        else:\n",
    "            print(f\"预测区间覆盖率(PICP): {picp}% (目标95%)\")\n",
    "            \n",
    "        nmpiw = metrics.get('NMPIW', 'N/A')\n",
    "        if isinstance(nmpiw, (int, float)) and not (isinstance(nmpiw, float) and np.isnan(nmpiw)):\n",
    "            print(f\"平均预测区间宽度(NMPIW): {nmpiw:.4f}\")\n",
    "        else:\n",
    "            print(f\"平均预测区间宽度(NMPIW): {nmpiw}\")\n",
    "            \n",
    "        calibration_error = metrics.get('calibration_error', 'N/A')\n",
    "        if isinstance(calibration_error, (int, float)) and not (isinstance(calibration_error, float) and np.isnan(calibration_error)):\n",
    "            print(f\"校准误差: {calibration_error:.2f}%\")\n",
    "        else:\n",
    "            print(f\"校准误差: {calibration_error}\")\n",
    "            \n",
    "\n",
    "            \n",
    "        avg_uncertainty = metrics.get('avg_uncertainty', 'N/A')\n",
    "        if isinstance(avg_uncertainty, (int, float)) and not (isinstance(avg_uncertainty, float) and np.isnan(avg_uncertainty)):\n",
    "            print(f\"平均不确定性(标准差): {avg_uncertainty:.4f}\")\n",
    "        else:\n",
    "            print(f\"平均不确定性(标准差): {avg_uncertainty}\")\n",
    "    \n",
    "    if 'PIR' in metrics and metrics['PIR'] is not None:\n",
    "        pir = metrics.get('PIR', 'N/A')\n",
    "        if isinstance(pir, (int, float)) and not (isinstance(pir, float) and np.isnan(pir)):\n",
    "            print(f\"\\n相比基线的改进率:\")\n",
    "            print(f\"RMSD改进率(PIR): {pir:.2f}%\")\n",
    "        else:\n",
    "            print(f\"\\n相比基线的改进率:\")\n",
    "            print(f\"RMSD改进率(PIR): {pir}\")\n",
    "\n",
    "    \n",
    "    # 尝试可视化一个样本的预测与置信区间\n",
    "    # 尝试可视化一个样本的预测与置信区间\n",
    "    try:\n",
    "        sample_idx = 0  # 选择第一个样本进行可视化\n",
    "        \n",
    "        # 检查数据维度并适应相应的可视化方法\n",
    "        if len(all_predictions.shape) == 3 and all_predictions.shape[0] > 0 and all_predictions.shape[1] > 0 and all_predictions.shape[2] > 0:\n",
    "            # 3D数据: [batch, building, forecast]\n",
    "            max_horizon = min(10, all_predictions.shape[2])  # 限制显示的预测长度\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            try:\n",
    "                plt.fill_between(\n",
    "                    range(max_horizon),\n",
    "                    all_lower_bounds.reshape(all_predictions.shape)[sample_idx, 0, :max_horizon],\n",
    "                    all_upper_bounds.reshape(all_predictions.shape)[sample_idx, 0, :max_horizon],\n",
    "                    alpha=0.3, color='blue', label='95% Confidence Interval'\n",
    "                )\n",
    "                plt.plot(range(max_horizon), all_predictions[sample_idx, 0, :max_horizon], 'b-o', label='Predictions')\n",
    "                plt.plot(range(max_horizon), all_targets[sample_idx, 0, :max_horizon], 'r-x', label='Ground Truth')\n",
    "            except Exception as e:\n",
    "                print(f\"3D data visualization error: {str(e)}\")\n",
    "                # Try simplified visualization\n",
    "                plt.plot(range(max_horizon), all_predictions[sample_idx, 0, :max_horizon], 'b-o', label='Predictions')\n",
    "                plt.plot(range(max_horizon), all_targets[sample_idx, 0, :max_horizon], 'r-x', label='Ground Truth')\n",
    "        \n",
    "        # 2D数据的情况\n",
    "        elif len(all_predictions.shape) == 2 and all_predictions.shape[0] > 0 and all_predictions.shape[1] > 0:\n",
    "            max_horizon = min(10, all_predictions.shape[1])\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            try:\n",
    "                plt.fill_between(\n",
    "                    range(max_horizon),\n",
    "                    all_lower_bounds.reshape(all_predictions.shape)[sample_idx, :max_horizon],\n",
    "                    all_upper_bounds.reshape(all_predictions.shape)[sample_idx, :max_horizon],\n",
    "                    alpha=0.3, color='blue', label='95% Confidence Interval'\n",
    "                )\n",
    "                plt.plot(range(max_horizon), all_predictions[sample_idx, :max_horizon], 'b-o', label='Predictions')\n",
    "                plt.plot(range(max_horizon), all_targets[sample_idx, :max_horizon], 'r-x', label='Ground Truth')\n",
    "            except Exception as e:\n",
    "                print(f\"2D data visualization error: {str(e)}\")\n",
    "                # Try simplified visualization\n",
    "                plt.plot(range(max_horizon), all_predictions[sample_idx, :max_horizon], 'b-o', label='Predictions')\n",
    "                plt.plot(range(max_horizon), all_targets[sample_idx, :max_horizon], 'r-x', label='Ground Truth')\n",
    "        \n",
    "        # 1D数据的情况\n",
    "        elif len(all_predictions.shape) == 1 and all_predictions.shape[0] > 0:\n",
    "            max_points = min(10, all_predictions.shape[0])\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            try:\n",
    "                plt.fill_between(\n",
    "                    range(max_points),\n",
    "                    all_lower_bounds[:max_points],\n",
    "                    all_upper_bounds[:max_points],\n",
    "                    alpha=0.3, color='blue', label='95% Confidence Interval'\n",
    "                )\n",
    "                plt.plot(range(max_points), all_predictions[:max_points], 'b-o', label='Predictions')\n",
    "                plt.plot(range(max_points), all_targets[:max_points], 'r-x', label='Ground Truth')\n",
    "            except Exception as e:\n",
    "                print(f\"1D data visualization error: {str(e)}\")\n",
    "                # Try the simplest visualization\n",
    "                plt.plot(range(max_points), all_predictions[:max_points], 'b-o', label='Predictions')\n",
    "                plt.plot(range(max_points), all_targets[:max_points], 'r-x', label='Ground Truth')\n",
    "        \n",
    "        else:\n",
    "            print(f\"Cannot visualize predictions: incompatible shape {all_predictions.shape}\")\n",
    "            return metrics\n",
    "        \n",
    "        plt.title(f'{model_name} Prediction Example\\nPICP: {metrics.get(\"PICP\", \"N/A\")}%')\n",
    "        plt.xlabel('Prediction Time Step')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Save the image, ensure the file name is valid\n",
    "        safe_model_name = ''.join(c if c.isalnum() or c in ['-', '_'] else '_' for c in model_name)\n",
    "        plt.savefig(f'prediction_sample_{safe_model_name}.png')\n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"创建可视化时出错: {str(e)}\")\n",
    "        print(f\"数据形状: 预测={all_predictions.shape}, 目标={all_targets.shape}, 下界={all_lower_bounds.shape}, 上界={all_upper_bounds.shape}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28a36c1-89bc-4ff3-acb1-0901a955762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bilstm import BaselineBiLSTM\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import copy\n",
    "from torch import optim\n",
    "from torch.autograd import Function\n",
    "\n",
    "# 配置日志：同时输出到文件和控制台，记录时间、等级和消息\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('training.log'),  # 日志文件\n",
    "        logging.StreamHandler()               # 控制台输出\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# ========================= DANN模型定义 =========================\n",
    "\n",
    "# 梯度反转层 - DANN的核心组件\n",
    "class GradientReversalFunction(Function):\n",
    "    \"\"\"\n",
    "    梯度反转层：前向传播时不变，反向传播时梯度反转\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.alpha, None\n",
    "\n",
    "class GradientReversal(nn.Module):\n",
    "    \"\"\"\n",
    "    梯度反转层的包装模块\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super(GradientReversal, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, self.alpha)\n",
    "\n",
    "class FeatureEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    特征编码器：提取时间序列特征\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=2, dropout=0.2):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 双向LSTM编码器\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # 特征投影层\n",
    "        self.feature_projection = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "        x: 输入张量 [batch_size, num_buildings, seq_len, input_dim]\n",
    "        \n",
    "        返回:\n",
    "        features: 编码后的特征 [batch_size, num_buildings, seq_len, hidden_dim]\n",
    "        \"\"\"\n",
    "        batch_size, num_buildings, seq_len, _ = x.shape\n",
    "        \n",
    "        # 重塑为[batch*buildings, seq_len, input_dim]\n",
    "        x_reshaped = x.reshape(batch_size * num_buildings, seq_len, -1)\n",
    "        \n",
    "        # LSTM编码\n",
    "        lstm_out, _ = self.lstm(x_reshaped)  # [batch*buildings, seq_len, hidden_dim*2]\n",
    "        \n",
    "        # 特征投影\n",
    "        projected_features = self.feature_projection(lstm_out)  # [batch*buildings, seq_len, hidden_dim]\n",
    "        \n",
    "        # 重塑回[batch, buildings, seq_len, hidden_dim]\n",
    "        features = projected_features.reshape(batch_size, num_buildings, seq_len, -1)\n",
    "        \n",
    "        return features\n",
    "\n",
    "class LabelPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    标签预测器：预测目标值\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim, category_dim, forecast_horizon, dropout=0.2):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "        # 类别嵌入层\n",
    "        self.category_embedding = nn.Sequential(\n",
    "            nn.Linear(category_dim, feature_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 预测层\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(feature_dim + feature_dim // 2, feature_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(feature_dim, forecast_horizon)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features, category_onehot):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "        features: 编码后的特征 [batch_size, num_buildings, seq_len, feature_dim]\n",
    "        category_onehot: 类别one-hot编码 [batch_size, category_dim]\n",
    "        \n",
    "        返回:\n",
    "        predictions: 预测值 [batch_size, num_buildings, forecast_horizon]\n",
    "        \"\"\"\n",
    "        batch_size, num_buildings, seq_len, _ = features.shape\n",
    "        \n",
    "        # 只使用最后一个时间步的特征\n",
    "        last_step_features = features[:, :, -1, :]  # [batch, buildings, feature_dim]\n",
    "        \n",
    "        # 类别嵌入\n",
    "        category_embedded = self.category_embedding(category_onehot)  # [batch, feature_dim//2]\n",
    "        \n",
    "        # 扩展类别嵌入以匹配建筑物维度\n",
    "        category_expanded = category_embedded.unsqueeze(1).expand(-1, num_buildings, -1)  # [batch, buildings, feature_dim//2]\n",
    "        \n",
    "        # 连接特征和类别\n",
    "        combined = torch.cat([last_step_features, category_expanded], dim=2)  # [batch, buildings, feature_dim + feature_dim//2]\n",
    "        \n",
    "        # 预测\n",
    "        predictions = self.predictor(combined)  # [batch, buildings, forecast_horizon]\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "class DomainClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    域分类器：区分源域和目标域\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim, hidden_dim=64, dropout=0.2):\n",
    "        super(DomainClassifier, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # 域分类器网络\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "        features: 编码后的特征 [batch_size, feature_dim]\n",
    "        \n",
    "        返回:\n",
    "        domain_pred: 域预测 [batch_size, 1]\n",
    "        \"\"\"\n",
    "        return self.classifier(features)\n",
    "\n",
    "class DANN(nn.Module):\n",
    "    \"\"\"\n",
    "    Domain-Adversarial Neural Network (DANN)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, category_dim, forecast_horizon, \n",
    "                 num_buildings=1, num_layers=2, dropout=0.2, alpha=1.0):\n",
    "        super(DANN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.category_dim = category_dim\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.num_buildings = num_buildings\n",
    "        self.alpha = alpha\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # 特征编码器\n",
    "        self.feature_encoder = FeatureEncoder(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # 标签预测器\n",
    "        self.label_predictor = LabelPredictor(\n",
    "            feature_dim=hidden_dim,\n",
    "            category_dim=category_dim,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # 梯度反转层\n",
    "        self.grl = GradientReversal(alpha=alpha)\n",
    "        \n",
    "        # 域分类器\n",
    "        self.domain_classifier = DomainClassifier(\n",
    "            feature_dim=hidden_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, category_onehot, domain_idx=None):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "        x: 输入张量 [batch_size, num_buildings, seq_len, input_dim]\n",
    "        category_onehot: 类别one-hot编码 [batch_size, category_dim]\n",
    "        domain_idx: 域索引，用于兼容接口，实际不使用\n",
    "        \n",
    "        返回:\n",
    "        predictions: 预测值 [batch_size, num_buildings, forecast_horizon]\n",
    "        \"\"\"\n",
    "        # 特征提取\n",
    "        features = self.feature_encoder(x)\n",
    "        \n",
    "        # 标签预测\n",
    "        predictions = self.label_predictor(features, category_onehot)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_features(self, x):\n",
    "        \"\"\"\n",
    "        获取特征表示，用于域对抗训练\n",
    "        \n",
    "        参数:\n",
    "        x: 输入张量 [batch_size, num_buildings, seq_len, input_dim]\n",
    "        \n",
    "        返回:\n",
    "        features: 编码后的特征 [batch_size*num_buildings, hidden_dim]\n",
    "        \"\"\"\n",
    "        batch_size, num_buildings, seq_len, _ = x.shape\n",
    "        \n",
    "        # 特征提取\n",
    "        features = self.feature_encoder(x)  # [batch, buildings, seq_len, hidden_dim]\n",
    "        \n",
    "        # 只使用最后一个时间步的特征并展平\n",
    "        last_step_features = features[:, :, -1, :]  # [batch, buildings, hidden_dim]\n",
    "        flattened_features = last_step_features.reshape(batch_size * num_buildings, -1)\n",
    "        \n",
    "        return flattened_features\n",
    "    \n",
    "    def domain_classify(self, features):\n",
    "        \"\"\"\n",
    "        域分类，用于域对抗训练\n",
    "        \n",
    "        参数:\n",
    "        features: 编码后的特征 [batch_size, feature_dim]\n",
    "        \n",
    "        返回:\n",
    "        domain_pred: 域预测 [batch_size, 1]\n",
    "        \"\"\"\n",
    "        # 应用梯度反转\n",
    "        reversed_features = self.grl(features)\n",
    "        \n",
    "        # 域分类\n",
    "        domain_pred = self.domain_classifier(reversed_features)\n",
    "        \n",
    "        return domain_pred\n",
    "    \n",
    "    def set_alpha(self, alpha):\n",
    "        \"\"\"\n",
    "        设置梯度反转层的alpha值\n",
    "        \n",
    "        参数:\n",
    "        alpha: 梯度反转系数\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.grl.alpha = alpha\n",
    "\n",
    "# ========================= 损失函数和评估函数 =========================\n",
    "\n",
    "# 定义Huber损失函数\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super(HuberLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # 计算预测值与目标值之间的差异\n",
    "        diff = predictions - targets\n",
    "        abs_diff = torch.abs(diff)\n",
    "        \n",
    "        # 应用Huber损失公式\n",
    "        loss = torch.where(\n",
    "            abs_diff <= self.delta,\n",
    "            0.5 * diff * diff,\n",
    "            self.delta * (abs_diff - 0.5 * self.delta)\n",
    "        )\n",
    "        \n",
    "        return torch.mean(loss)\n",
    "\n",
    "# 计算损失的辅助函数\n",
    "def calculate_loss(predictions, targets):\n",
    "    \"\"\"\n",
    "    计算Huber损失\n",
    "    \n",
    "    参数:\n",
    "    - predictions: 预测值\n",
    "    - targets: 真实值\n",
    "    \n",
    "    返回:\n",
    "    - loss: Huber损失值\n",
    "    \"\"\"\n",
    "    loss_fn = HuberLoss(delta=1.0)\n",
    "    return loss_fn(predictions, targets)\n",
    "\n",
    "# 简化评估函数，适配DANN模型\n",
    "def simple_evaluate_model(model, test_loader, model_name=\"Model\", device='cuda', domain_idx=None):\n",
    "    \"\"\"\n",
    "    训练中使用的简化评估函数，适配DANN模型\n",
    "    \n",
    "    参数:\n",
    "    - model: 要评估的模型\n",
    "    - test_loader: 测试数据加载器\n",
    "    - model_name: 模型名称\n",
    "    - device: 计算设备\n",
    "    - domain_idx: 域索引(不使用，保留参数兼容性)\n",
    "    \n",
    "    返回:\n",
    "    - 简化的评估指标字典\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, _, category_onehot in test_loader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            category_onehot = category_onehot.float().to(device)\n",
    "            \n",
    "            # 使用DANN模型进行预测\n",
    "            predictions = model(inputs, category_onehot)\n",
    "            \n",
    "            # 收集预测和目标值\n",
    "            pred_values = predictions.cpu().numpy()\n",
    "            target_values = targets.cpu().numpy()\n",
    "            \n",
    "            all_preds.append(pred_values)\n",
    "            all_targets.append(target_values)\n",
    "    \n",
    "    # 合并所有批次的预测和目标\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    \n",
    "    # 展平数组以便计算指标\n",
    "    all_preds = all_preds.reshape(-1)\n",
    "    all_targets = all_targets.reshape(-1)\n",
    "    \n",
    "    # 计算基本指标\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    rmsd = np.sqrt(mse)\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "    \n",
    "    # 计算MAPE（排除零值）\n",
    "    mask = np.abs(all_targets) > 1e-6\n",
    "    mape = np.mean(np.abs((all_targets[mask] - all_preds[mask]) / all_targets[mask])) * 100 if np.any(mask) else np.nan\n",
    "    \n",
    "    # 计算CC (相关系数)\n",
    "    cc = np.corrcoef(all_preds, all_targets)[0, 1]\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"RMSD\": rmsd,\n",
    "        \"R2\": r2,\n",
    "        \"MAPE\": mape,\n",
    "        \"CC\": cc\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3587c741-d9d0-4592-80f0-98e1fa0604b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "加载所有类别的训练数据...\n",
      "加载天气数据: Gator_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Gator_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Rat_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Rat_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Wolf_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Wolf_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Eagle_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Eagle_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Robin_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Robin_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Hog_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Hog_mild_test.csv, 形状: (6600, 5)\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 DO 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 DO 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 HO 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 HO 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 LI 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 LI 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 OF 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 OF 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 UL 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 UL 测试数据集长度: 6552\n",
      "跳过类别 CC 的训练数据集创建 (train为null或空)\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 CC 测试数据集长度: 6552\n",
      "输入形状: torch.Size([32, 5, 24, 6]), 目标形状: torch.Size([32, 5, 24]), 类别形状: torch.Size([32, 6])\n",
      "创建和训练DANN模型...\n",
      "开始训练 dann_source_huber...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd913d03a093493b8b3b60011ab27cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1415451a6c824d1fa9db8b4e654bcd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 1), 验证损失: 0.0085\n",
      "Epoch 1/10 - Train Loss: 0.0190, Val Loss: 0.0085, RMSD: 0.1305, R²: 0.5359, Best Val Loss: 0.0085 (Epoch 1), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc8d0fb75a3430691a4ef890aa0a5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e463facb284d8aa2b6e45c248a4f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 2), 验证损失: 0.0084\n",
      "Epoch 2/10 - Train Loss: 0.0102, Val Loss: 0.0084, RMSD: 0.1300, R²: 0.5398, Best Val Loss: 0.0084 (Epoch 2), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c75ebfc3704c12abba83ae5cb5eed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf026f78e3f4173b9414ac8d8450512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 3), 验证损失: 0.0066\n",
      "Epoch 3/10 - Train Loss: 0.0090, Val Loss: 0.0066, RMSD: 0.1150, R²: 0.6396, Best Val Loss: 0.0066 (Epoch 3), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24661470d7d49a99005dd4261c26bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d369d6cc7b405d820be0b7bd01f8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 4), 验证损失: 0.0044\n",
      "Epoch 4/10 - Train Loss: 0.0070, Val Loss: 0.0044, RMSD: 0.0941, R²: 0.7586, Best Val Loss: 0.0044 (Epoch 4), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251e01f8fac4460799e1ffac04088745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b3159ff9714253af6414a45a274074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 5), 验证损失: 0.0042\n",
      "Epoch 5/10 - Train Loss: 0.0055, Val Loss: 0.0042, RMSD: 0.0913, R²: 0.7731, Best Val Loss: 0.0042 (Epoch 5), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b503b871e504f339804292ddf922d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972620e060f04f96bc0074da59cdc5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 6), 验证损失: 0.0042\n",
      "Epoch 6/10 - Train Loss: 0.0052, Val Loss: 0.0042, RMSD: 0.0911, R²: 0.7739, Best Val Loss: 0.0042 (Epoch 6), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d2d8e1886f4b25938f7389286fb842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a947bf40c484ba3b368fa13f47664e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 7), 验证损失: 0.0040\n",
      "Epoch 7/10 - Train Loss: 0.0050, Val Loss: 0.0040, RMSD: 0.0897, R²: 0.7808, Best Val Loss: 0.0040 (Epoch 7), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e1bf6a32cd489ba7eab44cf13c6b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae5cf01e8794559a68880f004c12492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 8), 验证损失: 0.0040\n",
      "Epoch 8/10 - Train Loss: 0.0049, Val Loss: 0.0040, RMSD: 0.0892, R²: 0.7834, Best Val Loss: 0.0040 (Epoch 8), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af57ac330d0435faf8737a0a960f407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80c6b39775a4568933fdb710c3d5ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存最佳模型 (epoch 9), 验证损失: 0.0039\n",
      "Epoch 9/10 - Train Loss: 0.0048, Val Loss: 0.0039, RMSD: 0.0889, R²: 0.7849, Best Val Loss: 0.0039 (Epoch 9), LR: 0.001000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048fb298162e48ddbf7d2dd4717cf761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [Training]:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4e8d5b180a45389e7f3e653201f078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [Validation]:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.0047, Val Loss: 0.0040, RMSD: 0.0897, R²: 0.7809, Best Val Loss: 0.0039 (Epoch 9), LR: 0.001000\n",
      "\n",
      "评估源域模型性能...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:05:44,488 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([10680, 64]), target_features.shape=torch.Size([10680, 64])\n",
      "2025-06-23 23:05:44,492 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (256320,)\n",
      "目标: (256320,)\n",
      "下界: (256320,)\n",
      "上界: (256320,)\n",
      "不确定性: (256320,)\n",
      "\n",
      "DANN_Source_Huber_Model 评估报告:\n",
      "RMSD: 0.08909539903381088\n",
      "MAPE: 16.58074188232422%\n",
      "R²: 0.7837463617324829\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.09280002117156982\n",
      "特征对齐质量: 0.30181360244750977\n",
      "MMD: 0.00023987889289855957\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 69.80% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.14853931963443756\n",
      "校准误差: 25.20%\n",
      "平均不确定性(标准差): 0.03841352090239525\n",
      "\n",
      "源域模型评估指标:\n",
      "MAPE(%): 16.58\n",
      "RMSD: 0.0891\n",
      "R²: 0.7837\n",
      "CC: 0.8858\n",
      "\n",
      "源域不确定性评估:\n",
      "预测区间覆盖率(PICP): 69.80% (目标95%)\n",
      "校准误差: 25.20%\n",
      "平均区间宽度(NMPIW): 0.1485\n",
      "不确定性质量分数(UQS): 0.5009\n",
      "训练完成！\n"
     ]
    }
   ],
   "source": [
    "def train_dann_source_model(model, train_loader, val_loader, epochs, lr, weight_decay, \n",
    "                           model_name, save_dir='models', device='cuda', early_stopping_patience=5):\n",
    "    \"\"\"\n",
    "    训练DANN源域模型\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 设置优化器和学习率调度器\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    # 初始化记录器\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # 保存模型配置信息\n",
    "    model_config = {\n",
    "        'input_dim': model.input_dim,\n",
    "        'hidden_dim': model.hidden_dim,\n",
    "        'category_dim': model.category_dim,\n",
    "        'forecast_horizon': model.forecast_horizon,\n",
    "        'num_buildings': model.num_buildings,\n",
    "        'num_layers': model.num_layers,\n",
    "        'dropout': model.dropout,\n",
    "        'model_type': 'DANN'\n",
    "    }\n",
    "    \n",
    "    # 保存最佳模型的信息\n",
    "    best_model_info = {\n",
    "        'state_dict': None,\n",
    "        'optimizer_state': None,\n",
    "        'epoch': 0,\n",
    "        'train_loss': float('inf'),\n",
    "        'val_loss': float('inf'),\n",
    "        'metrics': None\n",
    "    }\n",
    "\n",
    "    print(f\"开始训练 {model_name}...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        train_steps = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Training]')\n",
    "        for batch in progress_bar:\n",
    "            inputs, targets, category, category_onehot = [\n",
    "                x.float().to(device) if torch.is_tensor(x) else x for x in batch\n",
    "            ]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播 - 只进行标签预测任务\n",
    "            predictions = model(inputs, category_onehot)\n",
    "            \n",
    "            # 计算任务损失\n",
    "            loss = calculate_loss(predictions, targets)  # 使用Huber损失函数\n",
    "            \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "            progress_bar.set_postfix({'train_loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / train_steps\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        val_steps = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Validation]')\n",
    "            for batch in progress_bar:\n",
    "                inputs, targets, category, category_onehot = [\n",
    "                    x.float().to(device) if torch.is_tensor(x) else x for x in batch\n",
    "                ]\n",
    "                \n",
    "                # 前向传播\n",
    "                predictions = model(inputs, category_onehot)\n",
    "                \n",
    "                # 计算损失\n",
    "                loss = calculate_loss(predictions, targets)\n",
    "                \n",
    "                epoch_val_loss += loss.item()\n",
    "                val_steps += 1\n",
    "                progress_bar.set_postfix({'val_loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_val_loss = epoch_val_loss / val_steps\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # 学习率调整\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # 计算当前模型的评估指标\n",
    "        current_metrics = simple_evaluate_model(model, val_loader, f\"{model_name}_epoch_{epoch+1}\", device=device)\n",
    "        \n",
    "        # 检查是否是最佳模型\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # 更新最佳模型信息\n",
    "            best_model_info = {\n",
    "                'state_dict': copy.deepcopy(model.state_dict()),\n",
    "                'optimizer_state': copy.deepcopy(optimizer.state_dict()),\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'metrics': current_metrics,\n",
    "                'hyperparameters': {\n",
    "                    'lr': lr,\n",
    "                    'weight_decay': weight_decay,\n",
    "                    'epochs': epochs,\n",
    "                    'best_epoch': epoch + 1,\n",
    "                    'model_config': model_config,\n",
    "                    'model_type': 'DANN'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # 保存最佳模型检查点\n",
    "            checkpoint_path = os.path.join(save_dir, f'{model_name}_best.pth')\n",
    "            torch.save(best_model_info, checkpoint_path)\n",
    "            print(f\"✅ 保存最佳模型 (epoch {epoch+1}), 验证损失: {avg_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # 打印当前epoch的训练信息\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} - \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "            f\"RMSD: {current_metrics['RMSD']:.4f}, \"\n",
    "            f\"R²: {current_metrics['R2']:.4f}, \"\n",
    "            f\"Best Val Loss: {best_val_loss:.4f} (Epoch {best_epoch+1}), \"\n",
    "            f\"LR: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        )\n",
    "        \n",
    "        # 早停检查\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 训练结束后，保存训练历史\n",
    "    history = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'best_epoch': best_epoch + 1,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "    \n",
    "    # 保存训练历史\n",
    "    history_path = os.path.join(save_dir, f'{model_name}_training_history.json')\n",
    "    with open(history_path, 'w') as f:\n",
    "        # 将列表转换为可序列化格式\n",
    "        serializable_history = {\n",
    "            'train_losses': [float(loss) for loss in train_losses],\n",
    "            'val_losses': [float(loss) for loss in val_losses],\n",
    "            'best_epoch': best_epoch + 1,\n",
    "            'best_val_loss': float(best_val_loss)\n",
    "        }\n",
    "        json.dump(serializable_history, f, indent=4)\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Model (Epoch {best_epoch+1})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{model_name} Training History')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_training_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 恢复最佳模型状态\n",
    "    model.load_state_dict(best_model_info['state_dict'])\n",
    "    \n",
    "    return model, best_model_info, history\n",
    "\n",
    "# 辅助函数：将对象转换为JSON可序列化的格式\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"将对象转换为JSON可序列化的格式\"\"\"\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        # 将张量转换为Python原生类型\n",
    "        obj = obj.detach().cpu().numpy()\n",
    "        if obj.size == 1:\n",
    "            return float(obj.item())  # 单个值转为float\n",
    "        return obj.tolist()  # 数组转为列表\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        # 将NumPy数组转换为列表\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64, np.int32, np.int64)):\n",
    "        # 将NumPy标量转换为Python标量\n",
    "        return float(obj) if np.issubdtype(obj.dtype, np.floating) else int(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        # 递归处理字典\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        # 递归处理列表\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, (float, int, str, bool, type(None))):\n",
    "        # 这些类型已经是JSON可序列化的\n",
    "        return obj\n",
    "    else:\n",
    "        # 其他类型，尝试转换为字符串\n",
    "        try:\n",
    "            return str(obj)\n",
    "        except:\n",
    "            return \"Non-serializable object\"\n",
    "\n",
    "# ========================= 主训练代码 =========================\n",
    "\n",
    "# 创建保存目录\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 模型参数设置\n",
    "batch_size = 32\n",
    "sequence_length = 24\n",
    "forecast_horizon = 24\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "epochs = 10  # 源域预训练轮次\n",
    "\n",
    "# 加载数据\n",
    "print(\"加载所有类别的训练数据...\")\n",
    "train_loader, test_loader, categories = create_all_dataloaders(\n",
    "    batch_size=batch_size, \n",
    "    sequence_length=sequence_length, \n",
    "    forecast_horizon=forecast_horizon\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "\n",
    "# 从train_loader中获取完整训练建筑数据集\n",
    "all_train_dataset = train_loader.dataset  # 这是ConcatDataset\n",
    "\n",
    "# 设定划分比例（如80%训练，20%验证）\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "total_len = len(all_train_dataset)\n",
    "train_len = int(total_len * train_ratio)\n",
    "val_len = total_len - train_len\n",
    "\n",
    "# 使用random_split划分\n",
    "train_subset, val_subset = random_split(all_train_dataset, [train_len, val_len])\n",
    "\n",
    "# 构建新的dataloader\n",
    "batch_size = train_loader.batch_size\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# 获取数据维度信息\n",
    "for inputs, targets, category, category_onehot in train_loader:\n",
    "    print(f\"输入形状: {inputs.shape}, 目标形状: {targets.shape}, 类别形状: {category_onehot.shape}\")\n",
    "    input_dim = inputs.shape[-1]\n",
    "    num_buildings = inputs.shape[1]\n",
    "    category_dim = category_onehot.shape[-1]\n",
    "    break\n",
    "\n",
    "# 创建DANN模型\n",
    "print(\"创建和训练DANN模型...\")\n",
    "\n",
    "# 创建DANN模型\n",
    "source_model = DANN(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    category_dim=category_dim,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    num_buildings=num_buildings,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    alpha=0.0  # 源域训练时不使用域对抗，设置alpha为0\n",
    ")\n",
    "\n",
    "# 训练源域模型\n",
    "trained_source_model, source_best_info, source_history = train_dann_source_model(\n",
    "    model=source_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=epochs,\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    model_name='dann_source_huber',\n",
    "    save_dir='models',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# 使用改进的完整评估函数对最终模型进行评估\n",
    "print(\"\\n评估源域模型性能...\")\n",
    "source_metrics = evaluate_model(\n",
    "    model=trained_source_model, \n",
    "    test_loader=val_loader,\n",
    "    model_name=\"DANN_Source_Huber_Model\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# 提取重要的评估指标\n",
    "print(\"\\n源域模型评估指标:\")\n",
    "print(f\"MAPE(%): {source_metrics['MAPE']:.2f}\")\n",
    "print(f\"RMSD: {source_metrics['RMSD']:.4f}\")\n",
    "print(f\"R²: {source_metrics['R2']:.4f}\")\n",
    "if 'CC' in source_metrics:\n",
    "    print(f\"CC: {source_metrics['CC']:.4f}\")\n",
    "\n",
    "# 打印源域的不确定性评估结果\n",
    "if 'PICP' in source_metrics:\n",
    "    print(\"\\n源域不确定性评估:\")\n",
    "    print(f\"预测区间覆盖率(PICP): {source_metrics['PICP']:.2f}% (目标95%)\")\n",
    "    print(f\"校准误差: {source_metrics['calibration_error']:.2f}%\")\n",
    "    print(f\"平均区间宽度(NMPIW): {source_metrics['NMPIW']:.4f}\")\n",
    "    print(f\"不确定性质量分数(UQS): {source_metrics['UQS']:.4f}\")\n",
    "\n",
    "# 保存最终评估结果\n",
    "metrics_path = os.path.join('models', 'dann_model_evaluation_metrics.json')\n",
    "with open(metrics_path, 'w') as f:\n",
    "    all_metrics = {\n",
    "        'source_domain': {k: convert_to_serializable(v) \n",
    "                         for k, v in source_metrics.items() if k != 'Model'},\n",
    "        'model_info': convert_to_serializable({\n",
    "            'best_epoch': source_best_info['epoch'],\n",
    "            'model_type': 'DANN'\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    json.dump(all_metrics, f, indent=4)\n",
    "\n",
    "print(\"训练完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69208b-e7ef-4d98-ab5d-6a38ef081422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载所有类别的训练数据...\n",
      "加载天气数据: Gator_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Gator_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Rat_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Rat_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Wolf_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Wolf_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Eagle_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Eagle_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Robin_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Robin_mild_test.csv, 形状: (6600, 5)\n",
      "加载天气数据: Hog_mild_train.csv, 形状: (2184, 5)\n",
      "加载天气数据: Hog_mild_test.csv, 形状: (6600, 5)\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 DO 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 DO 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 HO 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 HO 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 LI 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 LI 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 OF 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 OF 测试数据集长度: 6552\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "类别 UL 训练数据集长度: 2136\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 UL 测试数据集长度: 6552\n",
      "跳过类别 CC 的训练数据集创建 (train为null或空)\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 CC 测试数据集长度: 6552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:05:45,619 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([32, 5, 24, 6]), 目标形状: torch.Size([32, 5, 24]), 类别形状: torch.Size([32, 6])\n",
      "创建DANN模型...\n",
      "训练源域DANN模型...\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(DO), Shortage: mild\n",
      "为类别 DO 创建数据加载器 (shortage: mild)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "成功创建 DO 的数据加载器，共 10824 个样本\n",
      "🔄 使用DANN进行迁移学习 for category DO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1365ed0d66c84d06b2158fd128dd5625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:06:30,757 - INFO - Epoch 1/15 - Loss: 0.0431, Task: 0.0431, Domain: 0.6934, RMSE: 0.1251, Alpha: 0.0000\n",
      "2025-06-23 23:06:30,760 - INFO - 发现新的最佳RMSE: 0.1251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb03cdcc73e749bbbedac7c84f764503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:07:14,473 - INFO - Epoch 2/15 - Loss: 0.0971, Task: 0.0136, Domain: 0.6488, RMSE: 0.1165, Alpha: 0.1286\n",
      "2025-06-23 23:07:14,476 - INFO - 发现新的最佳RMSE: 0.1165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc19805f8ff34b6ba4430df42b34db54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:07:58,674 - INFO - Epoch 3/15 - Loss: 0.1737, Task: 0.0140, Domain: 0.6848, RMSE: 0.1224, Alpha: 0.2331\n",
      "2025-06-23 23:07:58,675 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9074cdf672e4e99aa09e092abf8d7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:08:42,378 - INFO - Epoch 4/15 - Loss: 0.2254, Task: 0.0145, Domain: 0.6922, RMSE: 0.1394, Alpha: 0.3046\n",
      "2025-06-23 23:08:42,380 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe17c5bbf5504bc392718c47f5350bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:09:26,742 - INFO - Epoch 5/15 - Loss: 0.2552, Task: 0.0142, Domain: 0.6925, RMSE: 0.1401, Alpha: 0.3480\n",
      "2025-06-23 23:09:26,743 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:09:26,744 - INFO - 触发早停，在epoch 5\n",
      "2025-06-23 23:09:26,746 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:09:26,750 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category DO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:09:38,575 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([6552, 64]), target_features.shape=torch.Size([6552, 64])\n",
      "2025-06-23 23:09:38,578 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (157248,)\n",
      "目标: (157248,)\n",
      "下界: (157248,)\n",
      "上界: (157248,)\n",
      "不确定性: (157248,)\n",
      "\n",
      "DANN_TL_ALL_to_DO_mild 评估报告:\n",
      "RMSD: 0.11689814766728926\n",
      "MAPE: 19.505035400390625%\n",
      "R²: 0.07801908254623413\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.04439997673034668\n",
      "特征对齐质量: 0.689292311668396\n",
      "MMD: 2.777576446533203e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 76.94% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3879067301750183\n",
      "校准误差: 18.06%\n",
      "平均不确定性(标准差): 0.06953394412994385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:09:39,031 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: DO/mild transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(DO), Shortage: heavy\n",
      "为类别 DO 创建数据加载器 (shortage: heavy)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 624 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8064 个有效样本\n",
      "成功创建 DO 的数据加载器，共 9312 个样本\n",
      "🔄 使用DANN进行迁移学习 for category DO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca67b4e4222488097e9a492985e502d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:10:30,080 - INFO - Epoch 1/15 - Loss: 0.0425, Task: 0.0425, Domain: 0.6941, RMSE: 0.1219, Alpha: 0.0000\n",
      "2025-06-23 23:10:30,082 - INFO - 发现新的最佳RMSE: 0.1219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73794187cf754baa9fc93276845066ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:11:20,399 - INFO - Epoch 2/15 - Loss: 0.1045, Task: 0.0154, Domain: 0.6931, RMSE: 0.1131, Alpha: 0.1286\n",
      "2025-06-23 23:11:20,401 - INFO - 发现新的最佳RMSE: 0.1131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf086ab7b6e54855ba785ea8e117f4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:12:11,519 - INFO - Epoch 3/15 - Loss: 0.1744, Task: 0.0132, Domain: 0.6918, RMSE: 0.1118, Alpha: 0.2331\n",
      "2025-06-23 23:12:11,522 - INFO - 发现新的最佳RMSE: 0.1118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7891760f1e944999b10d4e0b1d7d1ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:13:02,501 - INFO - Epoch 4/15 - Loss: 0.2228, Task: 0.0127, Domain: 0.6897, RMSE: 0.1125, Alpha: 0.3046\n",
      "2025-06-23 23:13:02,502 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f3e2e07d8f47c3a6a3c55021b42593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:13:52,664 - INFO - Epoch 5/15 - Loss: 0.2529, Task: 0.0131, Domain: 0.6892, RMSE: 0.1163, Alpha: 0.3480\n",
      "2025-06-23 23:13:52,665 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b93a50b7864f3498918036c60d5542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:14:42,038 - INFO - Epoch 6/15 - Loss: 0.2738, Task: 0.0129, Domain: 0.7004, RMSE: 0.1122, Alpha: 0.3724\n",
      "2025-06-23 23:14:42,040 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:14:42,041 - INFO - 触发早停，在epoch 6\n",
      "2025-06-23 23:14:42,044 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:14:42,049 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category DO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:14:56,475 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8064, 64]), target_features.shape=torch.Size([8064, 64])\n",
      "2025-06-23 23:14:56,478 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (193536,)\n",
      "目标: (193536,)\n",
      "下界: (193536,)\n",
      "上界: (193536,)\n",
      "不确定性: (193536,)\n",
      "\n",
      "DANN_TL_ALL_to_DO_heavy 评估报告:\n",
      "RMSD: 0.11199299224255695\n",
      "MAPE: 19.159982681274414%\n",
      "R²: 0.18813246488571167\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.07360005378723145\n",
      "特征对齐质量: 0.6781001091003418\n",
      "MMD: 2.390146255493164e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 68.72% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3254561424255371\n",
      "校准误差: 26.28%\n",
      "平均不确定性(标准差): 0.058339402079582214\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: DO/heavy transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(DO), Shortage: extreme\n",
      "为类别 DO 创建数据加载器 (shortage: extreme)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:14:56,953 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 120 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8568 个有效样本\n",
      "成功创建 DO 的数据加载器，共 8808 个样本\n",
      "🔄 使用DANN进行迁移学习 for category DO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916ebef224f6465082fc6e6d6a531db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:15:49,538 - INFO - Epoch 1/15 - Loss: 0.0411, Task: 0.0411, Domain: 0.6939, RMSE: 0.1219, Alpha: 0.0000\n",
      "2025-06-23 23:15:49,540 - INFO - 发现新的最佳RMSE: 0.1219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1bdebdcec346e8b3ea1fccf9b06502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:16:40,513 - INFO - Epoch 2/15 - Loss: 0.1042, Task: 0.0153, Domain: 0.6907, RMSE: 0.1170, Alpha: 0.1286\n",
      "2025-06-23 23:16:40,516 - INFO - 发现新的最佳RMSE: 0.1170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ae72b04d1c4ad9926f369b95e7faf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:17:33,834 - INFO - Epoch 3/15 - Loss: 0.1743, Task: 0.0135, Domain: 0.6895, RMSE: 0.1139, Alpha: 0.2331\n",
      "2025-06-23 23:17:33,837 - INFO - 发现新的最佳RMSE: 0.1139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4550091e1b4c67956588de7111f6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:18:26,428 - INFO - Epoch 4/15 - Loss: 0.2232, Task: 0.0133, Domain: 0.6889, RMSE: 0.1200, Alpha: 0.3046\n",
      "2025-06-23 23:18:26,430 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7059722a75f0442787c6706f74def134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:19:17,878 - INFO - Epoch 5/15 - Loss: 0.2537, Task: 0.0136, Domain: 0.6899, RMSE: 0.1260, Alpha: 0.3480\n",
      "2025-06-23 23:19:17,880 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b33f3214bf242e1943ec1598fad8d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:20:09,983 - INFO - Epoch 6/15 - Loss: 0.3418, Task: 0.0229, Domain: 0.8564, RMSE: 0.1528, Alpha: 0.3724\n",
      "2025-06-23 23:20:09,985 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:20:09,986 - INFO - 触发早停，在epoch 6\n",
      "2025-06-23 23:20:09,988 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:20:09,992 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category DO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:20:25,381 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8568, 64]), target_features.shape=torch.Size([8568, 64])\n",
      "2025-06-23 23:20:25,384 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (205632,)\n",
      "目标: (205632,)\n",
      "下界: (205632,)\n",
      "上界: (205632,)\n",
      "不确定性: (205632,)\n",
      "\n",
      "DANN_TL_ALL_to_DO_extreme 评估报告:\n",
      "RMSD: 0.1143115683385197\n",
      "MAPE: 19.730510711669922%\n",
      "R²: 0.18921321630477905\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.07039999961853027\n",
      "特征对齐质量: 0.6783804893493652\n",
      "MMD: 2.491474151611328e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 67.69% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.2952978312969208\n",
      "校准误差: 27.31%\n",
      "平均不确定性(标准差): 0.05863453820347786\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: DO/extreme transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(HO), Shortage: mild\n",
      "为类别 HO 创建数据加载器 (shortage: mild)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:20:25,846 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "成功创建 HO 的数据加载器，共 10824 个样本\n",
      "🔄 使用DANN进行迁移学习 for category HO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800d44c51fe842649ca031d4d23b268d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:21:12,534 - INFO - Epoch 1/15 - Loss: 0.0615, Task: 0.0615, Domain: 0.6936, RMSE: 0.0985, Alpha: 0.0000\n",
      "2025-06-23 23:21:12,537 - INFO - 发现新的最佳RMSE: 0.0985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c314887d2f24175b62ca49577b4d8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:21:57,670 - INFO - Epoch 2/15 - Loss: 0.1030, Task: 0.0184, Domain: 0.6575, RMSE: 0.0811, Alpha: 0.1286\n",
      "2025-06-23 23:21:57,673 - INFO - 发现新的最佳RMSE: 0.0811\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26de9c379f714d4cb8d4c85d9aa23cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:22:42,602 - INFO - Epoch 3/15 - Loss: 0.1755, Task: 0.0166, Domain: 0.6814, RMSE: 0.1053, Alpha: 0.2331\n",
      "2025-06-23 23:22:42,603 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983339fb2cd34d469a83a40546e557df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:23:27,165 - INFO - Epoch 4/15 - Loss: 0.2258, Task: 0.0161, Domain: 0.6886, RMSE: 0.1165, Alpha: 0.3046\n",
      "2025-06-23 23:23:27,166 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82de273a0a624771ad0acbe9151be961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:24:11,260 - INFO - Epoch 5/15 - Loss: 0.2551, Task: 0.0162, Domain: 0.6867, RMSE: 0.1168, Alpha: 0.3480\n",
      "2025-06-23 23:24:11,261 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:24:11,262 - INFO - 触发早停，在epoch 5\n",
      "2025-06-23 23:24:11,264 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:24:11,268 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category HO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:24:23,505 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([6552, 64]), target_features.shape=torch.Size([6552, 64])\n",
      "2025-06-23 23:24:23,507 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (157248,)\n",
      "目标: (157248,)\n",
      "下界: (157248,)\n",
      "上界: (157248,)\n",
      "不确定性: (157248,)\n",
      "\n",
      "DANN_TL_ALL_to_HO_mild 评估报告:\n",
      "RMSD: 0.08231927623822415\n",
      "MAPE: 11.316866874694824%\n",
      "R²: 0.4981638789176941\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.08840000629425049\n",
      "特征对齐质量: 0.6918350458145142\n",
      "MMD: 4.2557716369628906e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 96.15% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3765060007572174\n",
      "校准误差: 1.15%\n",
      "平均不确定性(标准差): 0.09145060181617737\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: HO/mild transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(HO), Shortage: heavy\n",
      "为类别 HO 创建数据加载器 (shortage: heavy)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:24:23,989 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 624 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8064 个有效样本\n",
      "成功创建 HO 的数据加载器，共 9312 个样本\n",
      "🔄 使用DANN进行迁移学习 for category HO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885f0f579a61445baec934c8ba54403a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:25:14,971 - INFO - Epoch 1/15 - Loss: 0.0554, Task: 0.0554, Domain: 0.6944, RMSE: 0.0766, Alpha: 0.0000\n",
      "2025-06-23 23:25:14,974 - INFO - 发现新的最佳RMSE: 0.0766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bfc5a2010f4fe7a8f5057cc55802d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:26:05,997 - INFO - Epoch 2/15 - Loss: 0.1028, Task: 0.0150, Domain: 0.6827, RMSE: 0.0701, Alpha: 0.1286\n",
      "2025-06-23 23:26:06,000 - INFO - 发现新的最佳RMSE: 0.0701\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f6f8db60954badbb252df350e3b883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:26:58,612 - INFO - Epoch 3/15 - Loss: 0.1726, Task: 0.0131, Domain: 0.6842, RMSE: 0.0728, Alpha: 0.2331\n",
      "2025-06-23 23:26:58,614 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c50907c417c4c36b9e7cc66d71f6d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:27:48,741 - INFO - Epoch 4/15 - Loss: 0.2222, Task: 0.0128, Domain: 0.6873, RMSE: 0.0949, Alpha: 0.3046\n",
      "2025-06-23 23:27:48,742 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42010b168b82419aa6bf644f090059b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:28:41,665 - INFO - Epoch 5/15 - Loss: 0.2526, Task: 0.0129, Domain: 0.6888, RMSE: 0.1018, Alpha: 0.3480\n",
      "2025-06-23 23:28:41,667 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:28:41,668 - INFO - 触发早停，在epoch 5\n",
      "2025-06-23 23:28:41,670 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:28:41,674 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category HO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:28:56,550 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8064, 64]), target_features.shape=torch.Size([8064, 64])\n",
      "2025-06-23 23:28:56,552 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (193536,)\n",
      "目标: (193536,)\n",
      "下界: (193536,)\n",
      "上界: (193536,)\n",
      "不确定性: (193536,)\n",
      "\n",
      "DANN_TL_ALL_to_HO_heavy 评估报告:\n",
      "RMSD: 0.07120566192667213\n",
      "MAPE: 9.99679183959961%\n",
      "R²: 0.5891153216362\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.0875999927520752\n",
      "特征对齐质量: 0.6919322609901428\n",
      "MMD: 3.0159950256347656e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 97.37% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.34563857316970825\n",
      "校准误差: 2.37%\n",
      "平均不确定性(标准差): 0.08382269740104675\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: HO/heavy transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(HO), Shortage: extreme\n",
      "为类别 HO 创建数据加载器 (shortage: extreme)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:28:57,035 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 120 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8568 个有效样本\n",
      "成功创建 HO 的数据加载器，共 8808 个样本\n",
      "🔄 使用DANN进行迁移学习 for category HO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8612f29c4c34ee4930bd9f0b5ce66f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:29:49,154 - INFO - Epoch 1/15 - Loss: 0.0506, Task: 0.0506, Domain: 0.6955, RMSE: 0.0770, Alpha: 0.0000\n",
      "2025-06-23 23:29:49,157 - INFO - 发现新的最佳RMSE: 0.0770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d12e5898e724944add3af209de2abaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:30:42,084 - INFO - Epoch 2/15 - Loss: 0.0987, Task: 0.0149, Domain: 0.6517, RMSE: 0.0994, Alpha: 0.1286\n",
      "2025-06-23 23:30:42,086 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a47f3fab3a141c59582088604b0858a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:31:34,297 - INFO - Epoch 3/15 - Loss: 0.1722, Task: 0.0144, Domain: 0.6769, RMSE: 0.0893, Alpha: 0.2331\n",
      "2025-06-23 23:31:34,298 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acc8020e4994d0cae6f0f35956e5984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:32:25,935 - INFO - Epoch 4/15 - Loss: 0.2220, Task: 0.0145, Domain: 0.6811, RMSE: 0.1195, Alpha: 0.3046\n",
      "2025-06-23 23:32:25,937 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:32:25,937 - INFO - 触发早停，在epoch 4\n",
      "2025-06-23 23:32:25,939 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:32:25,944 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category HO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:32:41,232 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8568, 64]), target_features.shape=torch.Size([8568, 64])\n",
      "2025-06-23 23:32:41,234 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (205632,)\n",
      "目标: (205632,)\n",
      "下界: (205632,)\n",
      "上界: (205632,)\n",
      "不确定性: (205632,)\n",
      "\n",
      "DANN_TL_ALL_to_HO_extreme 评估报告:\n",
      "RMSD: 0.07853433246175752\n",
      "MAPE: 11.030713081359863%\n",
      "R²: 0.48076385259628296\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.08239996433258057\n",
      "特征对齐质量: 0.6939665675163269\n",
      "MMD: 0.00013136863708496094\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 98.40% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.4240342378616333\n",
      "校准误差: 3.40%\n",
      "平均不确定性(标准差): 0.1029253900051117\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: HO/extreme transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(LI), Shortage: mild\n",
      "为类别 LI 创建数据加载器 (shortage: mild)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:32:41,715 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "成功创建 LI 的数据加载器，共 10824 个样本\n",
      "🔄 使用DANN进行迁移学习 for category LI...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342af434a47f44d0beda286a79cc696d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:33:29,118 - INFO - Epoch 1/15 - Loss: 0.0445, Task: 0.0445, Domain: 0.6944, RMSE: 0.1664, Alpha: 0.0000\n",
      "2025-06-23 23:33:29,121 - INFO - 发现新的最佳RMSE: 0.1664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e5dca3ac9944aa889acfa081a979f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:34:13,265 - INFO - Epoch 2/15 - Loss: 0.1055, Task: 0.0231, Domain: 0.6410, RMSE: 0.1596, Alpha: 0.1286\n",
      "2025-06-23 23:34:13,268 - INFO - 发现新的最佳RMSE: 0.1596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f94f401a80c4e0f9c3424d7d142dc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:34:57,678 - INFO - Epoch 3/15 - Loss: 0.1913, Task: 0.0269, Domain: 0.7052, RMSE: 0.1710, Alpha: 0.2331\n",
      "2025-06-23 23:34:57,679 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be90b745ae3f4191a7d44de2e4e2ca5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:35:41,995 - INFO - Epoch 4/15 - Loss: 0.2331, Task: 0.0275, Domain: 0.6749, RMSE: 0.1896, Alpha: 0.3046\n",
      "2025-06-23 23:35:41,996 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a254e548468744809af2b226651bdb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:36:25,879 - INFO - Epoch 5/15 - Loss: 0.2643, Task: 0.0296, Domain: 0.6746, RMSE: 0.2070, Alpha: 0.3480\n",
      "2025-06-23 23:36:25,880 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:36:25,881 - INFO - 触发早停，在epoch 5\n",
      "2025-06-23 23:36:25,883 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:36:25,887 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category LI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:36:38,264 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([6552, 64]), target_features.shape=torch.Size([6552, 64])\n",
      "2025-06-23 23:36:38,267 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (157248,)\n",
      "目标: (157248,)\n",
      "下界: (157248,)\n",
      "上界: (157248,)\n",
      "不确定性: (157248,)\n",
      "\n",
      "DANN_TL_ALL_to_LI_mild 评估报告:\n",
      "RMSD: 0.160209978209494\n",
      "MAPE: 36.394012451171875%\n",
      "R²: 0.3379175066947937\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.0764000415802002\n",
      "特征对齐质量: 0.6257621049880981\n",
      "MMD: 8.165836334228516e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 65.93% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.31751832365989685\n",
      "校准误差: 29.07%\n",
      "平均不确定性(标准差): 0.08099956810474396\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: LI/mild transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(LI), Shortage: heavy\n",
      "为类别 LI 创建数据加载器 (shortage: heavy)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 624 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8064 个有效样本\n",
      "成功创建 LI 的数据加载器，共 9312 个样本\n",
      "🔄 使用DANN进行迁移学习 for category LI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:36:38,930 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1968520a05a5420a8b1500c663422ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:37:28,849 - INFO - Epoch 1/15 - Loss: 0.0555, Task: 0.0555, Domain: 0.6957, RMSE: 0.1680, Alpha: 0.0000\n",
      "2025-06-23 23:37:28,852 - INFO - 发现新的最佳RMSE: 0.1680\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b15ab81c6741ef97f7b0d9a48a8e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:38:18,995 - INFO - Epoch 2/15 - Loss: 0.1192, Task: 0.0340, Domain: 0.6621, RMSE: 0.1496, Alpha: 0.1286\n",
      "2025-06-23 23:38:18,998 - INFO - 发现新的最佳RMSE: 0.1496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53300defb5942878db2de356a0da45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:39:09,110 - INFO - Epoch 3/15 - Loss: 0.1879, Task: 0.0286, Domain: 0.6835, RMSE: 0.1250, Alpha: 0.2331\n",
      "2025-06-23 23:39:09,114 - INFO - 发现新的最佳RMSE: 0.1250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e112546502984fffa345bc008a9892d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:39:59,487 - INFO - Epoch 4/15 - Loss: 0.2303, Task: 0.0231, Domain: 0.6800, RMSE: 0.1365, Alpha: 0.3046\n",
      "2025-06-23 23:39:59,488 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2616a1bf2964cfc817e5ff9f00c5228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:40:50,465 - INFO - Epoch 5/15 - Loss: 0.2584, Task: 0.0239, Domain: 0.6740, RMSE: 0.1517, Alpha: 0.3480\n",
      "2025-06-23 23:40:50,466 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ce64b9a4be4d97a85a19d5329b5eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:41:41,260 - INFO - Epoch 6/15 - Loss: 0.5876, Task: 0.0631, Domain: 1.4083, RMSE: 0.2158, Alpha: 0.3724\n",
      "2025-06-23 23:41:41,261 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:41:41,262 - INFO - 触发早停，在epoch 6\n",
      "2025-06-23 23:41:41,264 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:41:41,268 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category LI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:41:55,987 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8064, 64]), target_features.shape=torch.Size([8064, 64])\n",
      "2025-06-23 23:41:55,990 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (193536,)\n",
      "目标: (193536,)\n",
      "下界: (193536,)\n",
      "上界: (193536,)\n",
      "不确定性: (193536,)\n",
      "\n",
      "DANN_TL_ALL_to_LI_heavy 评估报告:\n",
      "RMSD: 0.12508269644156186\n",
      "MAPE: 26.234024047851562%\n",
      "R²: 0.5953530073165894\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.11240005493164062\n",
      "特征对齐质量: 0.43023625016212463\n",
      "MMD: 0.0002307891845703125\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 79.76% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3192121982574463\n",
      "校准误差: 15.24%\n",
      "平均不确定性(标准差): 0.0820537582039833\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: LI/heavy transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(LI), Shortage: extreme\n",
      "为类别 LI 创建数据加载器 (shortage: extreme)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:41:56,491 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 120 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8568 个有效样本\n",
      "成功创建 LI 的数据加载器，共 8808 个样本\n",
      "🔄 使用DANN进行迁移学习 for category LI...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b11f99ae09c4f89bbc4f382d36ba03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:42:48,922 - INFO - Epoch 1/15 - Loss: 0.0621, Task: 0.0621, Domain: 0.6943, RMSE: 0.1757, Alpha: 0.0000\n",
      "2025-06-23 23:42:48,925 - INFO - 发现新的最佳RMSE: 0.1757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922ea8122f7146ba938d768e752b8a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:43:41,056 - INFO - Epoch 2/15 - Loss: 0.1251, Task: 0.0379, Domain: 0.6775, RMSE: 0.1477, Alpha: 0.1286\n",
      "2025-06-23 23:43:41,059 - INFO - 发现新的最佳RMSE: 0.1477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f7d660ebfe404e8561bf7f90e18c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:44:33,133 - INFO - Epoch 3/15 - Loss: 0.1845, Task: 0.0290, Domain: 0.6667, RMSE: 0.1252, Alpha: 0.2331\n",
      "2025-06-23 23:44:33,137 - INFO - 发现新的最佳RMSE: 0.1252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31089f09093e4351ba51c175fc427f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:45:25,049 - INFO - Epoch 4/15 - Loss: 0.2306, Task: 0.0246, Domain: 0.6764, RMSE: 0.1335, Alpha: 0.3046\n",
      "2025-06-23 23:45:25,051 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9018f2cca53e4cc49dd314b523a7f49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:46:17,111 - INFO - Epoch 5/15 - Loss: 0.2631, Task: 0.0254, Domain: 0.6831, RMSE: 0.1429, Alpha: 0.3480\n",
      "2025-06-23 23:46:17,112 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bcfd18b90043648e926f7b5eba4fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:47:10,693 - INFO - Epoch 6/15 - Loss: 0.9284, Task: 0.0707, Domain: 2.3028, RMSE: 0.2087, Alpha: 0.3724\n",
      "2025-06-23 23:47:10,695 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:47:10,696 - INFO - 触发早停，在epoch 6\n",
      "2025-06-23 23:47:10,698 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:47:10,702 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category LI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:47:26,622 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8568, 64]), target_features.shape=torch.Size([8568, 64])\n",
      "2025-06-23 23:47:26,624 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (205632,)\n",
      "目标: (205632,)\n",
      "下界: (205632,)\n",
      "上界: (205632,)\n",
      "不确定性: (205632,)\n",
      "\n",
      "DANN_TL_ALL_to_LI_extreme 评估报告:\n",
      "RMSD: 0.1247345482527447\n",
      "MAPE: 28.096824645996094%\n",
      "R²: 0.604102373123169\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.13199996948242188\n",
      "特征对齐质量: 0.36831408739089966\n",
      "MMD: 0.00020492076873779297\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 77.06% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3099069595336914\n",
      "校准误差: 17.94%\n",
      "平均不确定性(标准差): 0.0801464393734932\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: LI/extreme transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(OF), Shortage: mild\n",
      "为类别 OF 创建数据加载器 (shortage: mild)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:47:27,181 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "成功创建 OF 的数据加载器，共 10824 个样本\n",
      "🔄 使用DANN进行迁移学习 for category OF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c8934ae88249e6b9d2db75e8c6db5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:48:11,443 - INFO - Epoch 1/15 - Loss: 0.1012, Task: 0.1012, Domain: 0.6936, RMSE: 0.2110, Alpha: 0.0000\n",
      "2025-06-23 23:48:11,445 - INFO - 发现新的最佳RMSE: 0.2110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4515db7563f643f1a7f72bad56a7b5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:48:56,411 - INFO - Epoch 2/15 - Loss: 0.1462, Task: 0.0570, Domain: 0.6932, RMSE: 0.2119, Alpha: 0.1286\n",
      "2025-06-23 23:48:56,413 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f499ab293b49f6bbda88ba49e4b5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:49:41,168 - INFO - Epoch 3/15 - Loss: 0.2156, Task: 0.0572, Domain: 0.6797, RMSE: 0.1999, Alpha: 0.2331\n",
      "2025-06-23 23:49:41,171 - INFO - 发现新的最佳RMSE: 0.1999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3ef556a4fe442a8acd731ffd0e27b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:50:26,290 - INFO - Epoch 4/15 - Loss: 0.2489, Task: 0.0386, Domain: 0.6902, RMSE: 0.1553, Alpha: 0.3046\n",
      "2025-06-23 23:50:26,293 - INFO - 发现新的最佳RMSE: 0.1553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed691a0ed8a492fb2ada761796cbc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:51:10,811 - INFO - Epoch 5/15 - Loss: 0.2665, Task: 0.0298, Domain: 0.6803, RMSE: 0.1581, Alpha: 0.3480\n",
      "2025-06-23 23:51:10,813 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf5861e781643c1807ef006f3651b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:51:54,603 - INFO - Epoch 6/15 - Loss: 0.2901, Task: 0.0281, Domain: 0.7034, RMSE: 0.1512, Alpha: 0.3724\n",
      "2025-06-23 23:51:54,606 - INFO - 发现新的最佳RMSE: 0.1512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124ffa6d42664591a1190ec8070861f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:52:39,707 - INFO - Epoch 7/15 - Loss: 0.2917, Task: 0.0237, Domain: 0.6950, RMSE: 0.1555, Alpha: 0.3856\n",
      "2025-06-23 23:52:39,709 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbb8fca45664c0490309e512cd44ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:53:24,225 - INFO - Epoch 8/15 - Loss: 0.2911, Task: 0.0209, Domain: 0.6884, RMSE: 0.1555, Alpha: 0.3925\n",
      "2025-06-23 23:53:24,227 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c8d6c9139c46c08d0dac32789f7a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:54:08,891 - INFO - Epoch 9/15 - Loss: 0.2931, Task: 0.0203, Domain: 0.6886, RMSE: 0.1572, Alpha: 0.3962\n",
      "2025-06-23 23:54:08,893 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:54:08,894 - INFO - 触发早停，在epoch 9\n",
      "2025-06-23 23:54:08,896 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:54:08,900 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category OF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:54:20,823 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([6552, 64]), target_features.shape=torch.Size([6552, 64])\n",
      "2025-06-23 23:54:20,826 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (157248,)\n",
      "目标: (157248,)\n",
      "下界: (157248,)\n",
      "上界: (157248,)\n",
      "不确定性: (157248,)\n",
      "\n",
      "DANN_TL_ALL_to_OF_mild 评估报告:\n",
      "RMSD: 0.15265760126365074\n",
      "MAPE: 22.806873321533203%\n",
      "R²: 0.4747413992881775\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.0875999927520752\n",
      "特征对齐质量: 0.3799768090248108\n",
      "MMD: 0.00019741058349609375\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 77.36% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3463304340839386\n",
      "校准误差: 17.64%\n",
      "平均不确定性(标准差): 0.08716829121112823\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: OF/mild transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(OF), Shortage: heavy\n",
      "为类别 OF 创建数据加载器 (shortage: heavy)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:54:21,427 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 624 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8064 个有效样本\n",
      "成功创建 OF 的数据加载器，共 9312 个样本\n",
      "🔄 使用DANN进行迁移学习 for category OF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e0fbae5a204526837f82594896654a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:55:12,001 - INFO - Epoch 1/15 - Loss: 0.0556, Task: 0.0556, Domain: 0.6935, RMSE: 0.2161, Alpha: 0.0000\n",
      "2025-06-23 23:55:12,004 - INFO - 发现新的最佳RMSE: 0.2161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfece73f455547448447a27884a9cb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:56:02,505 - INFO - Epoch 2/15 - Loss: 0.1068, Task: 0.0258, Domain: 0.6292, RMSE: 0.2175, Alpha: 0.1286\n",
      "2025-06-23 23:56:02,506 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91429366af864fccad211c463e57229b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:56:52,538 - INFO - Epoch 3/15 - Loss: 0.1874, Task: 0.0250, Domain: 0.6968, RMSE: 0.2256, Alpha: 0.2331\n",
      "2025-06-23 23:56:52,539 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd77802fe77f4d43a1be540c9a723a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:57:45,907 - INFO - Epoch 4/15 - Loss: 0.2360, Task: 0.0243, Domain: 0.6950, RMSE: 0.2264, Alpha: 0.3046\n",
      "2025-06-23 23:57:45,909 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-23 23:57:45,910 - INFO - 触发早停，在epoch 4\n",
      "2025-06-23 23:57:45,912 - INFO - 已恢复最佳模型\n",
      "2025-06-23 23:57:45,916 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category OF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:58:00,872 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8064, 64]), target_features.shape=torch.Size([8064, 64])\n",
      "2025-06-23 23:58:00,875 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (193536,)\n",
      "目标: (193536,)\n",
      "下界: (193536,)\n",
      "上界: (193536,)\n",
      "不确定性: (193536,)\n",
      "\n",
      "DANN_TL_ALL_to_OF_heavy 评估报告:\n",
      "RMSD: 0.2164812367795851\n",
      "MAPE: 29.319011688232422%\n",
      "R²: -0.08485805988311768\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.09759998321533203\n",
      "特征对齐质量: 0.6950231790542603\n",
      "MMD: 0.0001246929168701172\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 68.26% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3744775950908661\n",
      "校准误差: 26.74%\n",
      "平均不确定性(标准差): 0.09505877643823624\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: OF/heavy transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(OF), Shortage: extreme\n",
      "为类别 OF 创建数据加载器 (shortage: extreme)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-23 23:58:01,445 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 120 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8568 个有效样本\n",
      "成功创建 OF 的数据加载器，共 8808 个样本\n",
      "🔄 使用DANN进行迁移学习 for category OF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c41f0d2f6d4f6898d2df9cfe7227a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:58:53,622 - INFO - Epoch 1/15 - Loss: 0.0712, Task: 0.0712, Domain: 0.6941, RMSE: 0.2143, Alpha: 0.0000\n",
      "2025-06-23 23:58:53,625 - INFO - 发现新的最佳RMSE: 0.2143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a85708515834650a3c7ee8f4b23350d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:59:46,448 - INFO - Epoch 2/15 - Loss: 0.1246, Task: 0.0388, Domain: 0.6671, RMSE: 0.2155, Alpha: 0.1286\n",
      "2025-06-23 23:59:46,449 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a525a41c6e43caa4464f2e1347b818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:00:43,768 - INFO - Epoch 3/15 - Loss: 0.1991, Task: 0.0351, Domain: 0.7036, RMSE: 0.2129, Alpha: 0.2331\n",
      "2025-06-24 00:00:43,771 - INFO - 发现新的最佳RMSE: 0.2129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85195e099b9749f4b471199380e76cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:01:36,420 - INFO - Epoch 4/15 - Loss: 0.2396, Task: 0.0289, Domain: 0.6916, RMSE: 0.1926, Alpha: 0.3046\n",
      "2025-06-24 00:01:36,423 - INFO - 发现新的最佳RMSE: 0.1926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2594ab134c15448b9918eca37420722c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:02:28,648 - INFO - Epoch 5/15 - Loss: 0.2657, Task: 0.0238, Domain: 0.6952, RMSE: 0.1804, Alpha: 0.3480\n",
      "2025-06-24 00:02:28,651 - INFO - 发现新的最佳RMSE: 0.1804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7facbf22f4c144fe9c0791f7c2cb3fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:03:22,004 - INFO - Epoch 6/15 - Loss: 0.2937, Task: 0.0236, Domain: 0.7251, RMSE: 0.1662, Alpha: 0.3724\n",
      "2025-06-24 00:03:22,007 - INFO - 发现新的最佳RMSE: 0.1662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c12a7a2c474c8192a48869a5b56de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:04:14,860 - INFO - Epoch 7/15 - Loss: 0.3257, Task: 0.0354, Domain: 0.7527, RMSE: 0.1882, Alpha: 0.3856\n",
      "2025-06-24 00:04:14,862 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd3305bc74d45fc9836b3a4a53aeb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:05:07,949 - INFO - Epoch 8/15 - Loss: 0.2889, Task: 0.0181, Domain: 0.6898, RMSE: 0.1792, Alpha: 0.3925\n",
      "2025-06-24 00:05:07,951 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6076668569004a93ad8b112184a33e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:06:00,903 - INFO - Epoch 9/15 - Loss: 0.2884, Task: 0.0153, Domain: 0.6895, RMSE: 0.1771, Alpha: 0.3962\n",
      "2025-06-24 00:06:00,904 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-24 00:06:00,905 - INFO - 触发早停，在epoch 9\n",
      "2025-06-24 00:06:00,907 - INFO - 已恢复最佳模型\n",
      "2025-06-24 00:06:00,910 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category OF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:06:17,993 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8568, 64]), target_features.shape=torch.Size([8568, 64])\n",
      "2025-06-24 00:06:17,996 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (205632,)\n",
      "目标: (205632,)\n",
      "下界: (205632,)\n",
      "上界: (205632,)\n",
      "不确定性: (205632,)\n",
      "\n",
      "DANN_TL_ALL_to_OF_extreme 评估报告:\n",
      "RMSD: 0.16584108939156225\n",
      "MAPE: 21.737274169921875%\n",
      "R²: 0.36114221811294556\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.09280002117156982\n",
      "特征对齐质量: 0.38261550664901733\n",
      "MMD: 0.00017392635345458984\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 65.04% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.27051421999931335\n",
      "校准误差: 29.96%\n",
      "平均不确定性(标准差): 0.06994770467281342\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: OF/extreme transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(UL), Shortage: mild\n",
      "为类别 UL 创建数据加载器 (shortage: mild)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-24 00:06:18,458 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "成功创建 UL 的数据加载器，共 10824 个样本\n",
      "🔄 使用DANN进行迁移学习 for category UL...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a3261b6ed04ea985e38f88e473f0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:07:02,738 - INFO - Epoch 1/15 - Loss: 0.0304, Task: 0.0304, Domain: 0.6918, RMSE: 0.0707, Alpha: 0.0000\n",
      "2025-06-24 00:07:02,741 - INFO - 发现新的最佳RMSE: 0.0707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016bb09adbdd41259a3578de3c717869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:07:47,089 - INFO - Epoch 2/15 - Loss: 0.0840, Task: 0.0117, Domain: 0.5621, RMSE: 0.0821, Alpha: 0.1286\n",
      "2025-06-24 00:07:47,090 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a9fc0ebfe1412fb6ec64d08558972f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:08:33,430 - INFO - Epoch 3/15 - Loss: 0.3301, Task: 0.0283, Domain: 1.2948, RMSE: 0.1370, Alpha: 0.2331\n",
      "2025-06-24 00:08:33,432 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ab491dc759496b8ca2406e9afc1bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:09:18,658 - INFO - Epoch 4/15 - Loss: 0.2377, Task: 0.0227, Domain: 0.7058, RMSE: 0.1350, Alpha: 0.3046\n",
      "2025-06-24 00:09:18,659 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-24 00:09:18,660 - INFO - 触发早停，在epoch 4\n",
      "2025-06-24 00:09:18,662 - INFO - 已恢复最佳模型\n",
      "2025-06-24 00:09:18,666 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category UL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:09:30,340 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([6552, 64]), target_features.shape=torch.Size([6552, 64])\n",
      "2025-06-24 00:09:30,343 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (157248,)\n",
      "目标: (157248,)\n",
      "下界: (157248,)\n",
      "上界: (157248,)\n",
      "不确定性: (157248,)\n",
      "\n",
      "DANN_TL_ALL_to_UL_mild 评估报告:\n",
      "RMSD: 0.07110977817468045\n",
      "MAPE: 16.797117233276367%\n",
      "R²: 0.4220659136772156\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.04920005798339844\n",
      "特征对齐质量: 0.6820766925811768\n",
      "MMD: 8.749961853027344e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 93.14% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.4694012403488159\n",
      "校准误差: 1.86%\n",
      "平均不确定性(标准差): 0.06974895298480988\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: UL/mild transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(UL), Shortage: heavy\n",
      "为类别 UL 创建数据加载器 (shortage: heavy)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-24 00:09:30,815 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 624 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8064 个有效样本\n",
      "成功创建 UL 的数据加载器，共 9312 个样本\n",
      "🔄 使用DANN进行迁移学习 for category UL...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489ac8463d6b4b9cb2684e19f8021267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:10:22,307 - INFO - Epoch 1/15 - Loss: 0.0233, Task: 0.0233, Domain: 0.6959, RMSE: 0.0758, Alpha: 0.0000\n",
      "2025-06-24 00:10:22,310 - INFO - 发现新的最佳RMSE: 0.0758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986b765a944748aab52da6800c5cd4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:11:13,995 - INFO - Epoch 2/15 - Loss: 0.0729, Task: 0.0099, Domain: 0.4898, RMSE: 0.0802, Alpha: 0.1286\n",
      "2025-06-24 00:11:13,996 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2abe8d1abfc463db74959055dbec6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:12:05,293 - INFO - Epoch 3/15 - Loss: 0.4203, Task: 0.0184, Domain: 1.7242, RMSE: 0.1151, Alpha: 0.2331\n",
      "2025-06-24 00:12:05,295 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1efaf1fc115478088d3355295e4d0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:12:57,258 - INFO - Epoch 4/15 - Loss: 0.3168, Task: 0.0279, Domain: 0.9484, RMSE: 0.1528, Alpha: 0.3046\n",
      "2025-06-24 00:12:57,260 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-24 00:12:57,261 - INFO - 触发早停，在epoch 4\n",
      "2025-06-24 00:12:57,263 - INFO - 已恢复最佳模型\n",
      "2025-06-24 00:12:57,267 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category UL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:13:11,953 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8064, 64]), target_features.shape=torch.Size([8064, 64])\n",
      "2025-06-24 00:13:11,955 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (193536,)\n",
      "目标: (193536,)\n",
      "下界: (193536,)\n",
      "上界: (193536,)\n",
      "不确定性: (193536,)\n",
      "\n",
      "DANN_TL_ALL_to_UL_heavy 评估报告:\n",
      "RMSD: 0.07469752818483003\n",
      "MAPE: 18.21799659729004%\n",
      "R²: 0.38957685232162476\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.07079994678497314\n",
      "特征对齐质量: 0.6449477076530457\n",
      "MMD: 3.5762786865234375e-05\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 85.56% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3847990334033966\n",
      "校准误差: 9.44%\n",
      "平均不确定性(标准差): 0.05717789754271507\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: UL/heavy transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(UL), Shortage: extreme\n",
      "为类别 UL 创建数据加载器 (shortage: extreme)...\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n",
      "2025-06-24 00:13:12,423 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 120 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 8568 个有效样本\n",
      "成功创建 UL 的数据加载器，共 8808 个样本\n",
      "🔄 使用DANN进行迁移学习 for category UL...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3195c6fc4ad5471db8718fe1cc074dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:14:05,246 - INFO - Epoch 1/15 - Loss: 0.0217, Task: 0.0217, Domain: 0.6939, RMSE: 0.0687, Alpha: 0.0000\n",
      "2025-06-24 00:14:05,248 - INFO - 发现新的最佳RMSE: 0.0687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722a3f83dfa1404f9bdfa45379546f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:14:58,317 - INFO - Epoch 2/15 - Loss: 0.0903, Task: 0.0093, Domain: 0.6296, RMSE: 0.0675, Alpha: 0.1286\n",
      "2025-06-24 00:14:58,321 - INFO - 发现新的最佳RMSE: 0.0675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01bc17aed7245ca8e20677d793b195a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:15:51,350 - INFO - Epoch 3/15 - Loss: 0.1631, Task: 0.0090, Domain: 0.6612, RMSE: 0.0910, Alpha: 0.2331\n",
      "2025-06-24 00:15:51,352 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8a4b20ce3c4a0f933fc0cfd910c423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:16:46,659 - INFO - Epoch 4/15 - Loss: 0.2727, Task: 0.0196, Domain: 0.8309, RMSE: 0.0848, Alpha: 0.3046\n",
      "2025-06-24 00:16:46,660 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a135f46c9344a3099a0be20d7f11735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:17:40,018 - INFO - Epoch 5/15 - Loss: 0.2460, Task: 0.0108, Domain: 0.6759, RMSE: 0.0984, Alpha: 0.3480\n",
      "2025-06-24 00:17:40,020 - INFO - 未改进RMSE，耐心值: 3/3\n",
      "2025-06-24 00:17:40,021 - INFO - 触发早停，在epoch 5\n",
      "2025-06-24 00:17:40,023 - INFO - 已恢复最佳模型\n",
      "2025-06-24 00:17:40,027 - INFO - 模型已保存到 models/dann_adapted_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 评估DANN模型 for category UL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:17:56,305 - WARNING - 特征数量过大，进行采样: source_features.shape=torch.Size([8568, 64]), target_features.shape=torch.Size([8568, 64])\n",
      "2025-06-24 00:17:56,308 - INFO - 采样后: source_features.shape=torch.Size([5000, 64]), target_features.shape=torch.Size([5000, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状信息:\n",
      "预测: (205632,)\n",
      "目标: (205632,)\n",
      "下界: (205632,)\n",
      "上界: (205632,)\n",
      "不确定性: (205632,)\n",
      "\n",
      "DANN_TL_ALL_to_UL_extreme 评估报告:\n",
      "RMSD: 0.0676247152240525\n",
      "MAPE: 18.763206481933594%\n",
      "R²: 0.4998188018798828\n",
      "KL散度: N/A\n",
      "\n",
      "迁移学习评估:\n",
      "域间距离 (A-distance): 0.08039999008178711\n",
      "特征对齐质量: 0.6847361326217651\n",
      "MMD: 0.00024080276489257812\n",
      "\n",
      "不确定性评估:\n",
      "预测区间覆盖率(PICP): 88.86% (目标95%)\n",
      "平均预测区间宽度(NMPIW): 0.3868720233440399\n",
      "校准误差: 6.14%\n",
      "平均不确定性(标准差): 0.057485807687044144\n",
      "\n",
      "📊 基线模型 vs DANN模型 指标对比:\n",
      "Model           MAPE(%)    RMSD       CV-RMSE    SD_real    SD_pred    CC         R2         PIR(%)    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "❌ Error: UL/extreme transfer failed: 'PIR'\n",
      "\n",
      "🚀 [Transfer Learning] Source(ALL) ➜ Target(CC), Shortage: mild\n",
      "为类别 CC 创建数据加载器 (shortage: mild)...\n",
      "类别 CC 没有训练数据，使用特殊处理\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1383/3083306177.py\", line 642, in <module>\n",
      "    print_metrics_table([\n",
      "  File \"/root/electircity/calculate.py\", line 109, in print_metrics_table\n",
      "    pir_str = f\"{metrics['PIR']:.2f}\" if metrics['PIR'] is not None else \"N/A\"\n",
      "                                         ~~~~~~~^^^^^^^\n",
      "KeyError: 'PIR'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:17:57,128 - INFO - 开始DANN域自适应迁移学习训练...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronos数据集初始化: 5 个建筑, 2136 个有效样本\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "类别 CC 的训练数据为空 (train=null)\n",
      "类别 CC 没有训练数据，train_loader设为None\n",
      "Chronos数据集初始化: 1 个建筑, 6552 个有效样本\n",
      "CC类别数据加载器创建成功:\n",
      "  - combined_train_loader: 10690 样本 (包含所有其他类别 + CC训练时间段)\n",
      "  - target_test_loader: 6552 样本\n",
      "  - target_train_loader: 10 样本\n",
      "🔄 使用DANN进行迁移学习 for category CC...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290e80cb80aa4945aedaac5a90cae87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:19:05,083 - INFO - Epoch 1/15 - Loss: 0.0497, Task: 0.0497, Domain: 0.6940, RMSE: 0.2006, Alpha: 0.0000\n",
      "2025-06-24 00:19:05,086 - INFO - 发现新的最佳RMSE: 0.2006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e050ddaab5f14c768bb26ca95ed70ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:20:15,658 - INFO - Epoch 2/15 - Loss: 0.1096, Task: 0.0205, Domain: 0.6929, RMSE: 0.2021, Alpha: 0.1286\n",
      "2025-06-24 00:20:15,659 - INFO - 未改进RMSE，耐心值: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098c2146311d4eaebae50a475642b70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:21:23,645 - INFO - Epoch 3/15 - Loss: 0.1785, Task: 0.0169, Domain: 0.6930, RMSE: 0.2116, Alpha: 0.2331\n",
      "2025-06-24 00:21:23,648 - INFO - 未改进RMSE，耐心值: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb28de408f54b1886955943b43c9b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import bisect\n",
    "from bilstm import BaselineBiLSTM\n",
    "\n",
    "def create_combined_dataloaders(source_category, target_category, data_shortage, batch_size, sequence_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    构建合并数据加载器（源域：mild，目标域：指定缺失程度）\n",
    "    对于CC类别，使用所有其他类别的训练数据作为源域\n",
    "    \"\"\"\n",
    "    print(f\"为类别 {target_category} 创建数据加载器 (shortage: {data_shortage})...\")\n",
    "    \n",
    "    try:\n",
    "        # 正常类别的处理逻辑（非CC类别）\n",
    "        if train_test_labels[target_category][\"train\"] is not None:\n",
    "            # 源域使用完整 mild 数据\n",
    "            source_train_loader, source_test_loader, _ = create_category_dataloaders(\n",
    "                category=target_category,\n",
    "                batch_size=batch_size,\n",
    "                sequence_length=sequence_length,\n",
    "                forecast_horizon=forecast_horizon,\n",
    "                data_shortage='mild'\n",
    "            )\n",
    "\n",
    "            # 目标域使用指定数据缺失场景\n",
    "            target_train_loader, target_test_loader, _ = create_category_dataloaders(\n",
    "                category=target_category,\n",
    "                batch_size=batch_size,\n",
    "                sequence_length=sequence_length,\n",
    "                forecast_horizon=forecast_horizon,\n",
    "                data_shortage=data_shortage\n",
    "            )\n",
    "\n",
    "            # 检查数据加载器是否为None\n",
    "            if source_train_loader is None or target_train_loader is None:\n",
    "                print(f\"警告：无法创建 {target_category} 的数据加载器\")\n",
    "                return None, None, None, categories\n",
    "\n",
    "            class SingleBuildingWrapper(Dataset):\n",
    "                \"\"\"确保所有样本都只包含一个建筑的数据集包装器\"\"\"\n",
    "                def __init__(self, dataset):\n",
    "                    self.dataset = dataset\n",
    "\n",
    "                def __len__(self):\n",
    "                    return len(self.dataset)\n",
    "\n",
    "                def __getitem__(self, idx):\n",
    "                    # 获取原始样本\n",
    "                    data = self.dataset[idx]\n",
    "                    if isinstance(data, tuple) and len(data) >= 2:\n",
    "                        inputs, targets = data[0], data[1]\n",
    "                        \n",
    "                        # 检查并确保只使用一个建筑\n",
    "                        if inputs.shape[0] > 1:\n",
    "                            inputs = inputs[0:1]  # 只保留第一个建筑\n",
    "                            targets = targets[0:1]  # 同样只保留第一个建筑的目标\n",
    "                        \n",
    "                        # 重建tuple\n",
    "                        result = (inputs,) + (targets,) + data[2:]\n",
    "                        return result\n",
    "                    else:\n",
    "                        return data\n",
    "\n",
    "            # 使用包装器处理每个数据集\n",
    "            source_train_dataset = SingleBuildingWrapper(source_train_loader.dataset)\n",
    "            source_test_dataset = SingleBuildingWrapper(source_test_loader.dataset)\n",
    "            target_train_dataset = SingleBuildingWrapper(target_train_loader.dataset)\n",
    "            target_test_dataset = SingleBuildingWrapper(target_test_loader.dataset)\n",
    "\n",
    "            class CombinedDataset(Dataset):\n",
    "                def __init__(self, datasets):\n",
    "                    self.datasets = datasets\n",
    "                    self.lengths = [len(ds) for ds in datasets]\n",
    "                    self.cumulative_lengths = [0]\n",
    "                    for length in self.lengths:\n",
    "                        self.cumulative_lengths.append(self.cumulative_lengths[-1] + length)\n",
    "\n",
    "                def __len__(self):\n",
    "                    return sum(self.lengths)\n",
    "\n",
    "                def __getitem__(self, idx):\n",
    "                    dataset_idx = bisect.bisect_right(self.cumulative_lengths, idx) - 1\n",
    "                    sample_idx = idx - self.cumulative_lengths[dataset_idx]\n",
    "                    return self.datasets[dataset_idx][sample_idx]\n",
    "\n",
    "            # 合并处理后的数据集\n",
    "            combined_dataset = CombinedDataset([\n",
    "                source_train_dataset,\n",
    "                source_test_dataset,\n",
    "                target_train_dataset\n",
    "            ])\n",
    "\n",
    "            # 创建新的数据加载器\n",
    "            combined_train_loader = DataLoader(\n",
    "                combined_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # 目标测试集也需要使用单建筑格式\n",
    "            target_test_loader_single = DataLoader(\n",
    "                target_test_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # 目标训练集也需要使用单建筑格式\n",
    "            target_train_loader_single = DataLoader(\n",
    "                target_train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=0\n",
    "            )\n",
    "\n",
    "            print(f\"成功创建 {target_category} 的数据加载器，共 {len(combined_dataset)} 个样本\")\n",
    "            return combined_train_loader, target_test_loader_single, target_train_loader_single, categories\n",
    "        \n",
    "        # CC类别的特殊处理\n",
    "        else:\n",
    "            print(f\"类别 {target_category} 没有训练数据，使用特殊处理\")\n",
    "            \n",
    "            # 收集所有其他类别的训练数据作为源域\n",
    "            all_source_datasets = []\n",
    "            \n",
    "            for cat in categories:\n",
    "                if cat != target_category and train_test_labels[cat][\"train\"] is not None:\n",
    "                    # 加载其他类别的训练数据（使用mild数据）\n",
    "                    cat_train_loader, _, _ = create_category_dataloaders(\n",
    "                        category=cat,\n",
    "                        batch_size=batch_size,\n",
    "                        sequence_length=sequence_length,\n",
    "                        forecast_horizon=forecast_horizon,\n",
    "                        data_shortage='mild'  # 源域使用完整数据\n",
    "                    )\n",
    "                    if cat_train_loader is not None:\n",
    "                        all_source_datasets.append(cat_train_loader.dataset)\n",
    "            \n",
    "            # 获取CC类别的测试数据（作为目标域）\n",
    "            _, cc_test_loader, _ = create_category_dataloaders(\n",
    "                category=target_category,\n",
    "                batch_size=batch_size,\n",
    "                sequence_length=sequence_length,\n",
    "                forecast_horizon=forecast_horizon,\n",
    "                data_shortage=data_shortage\n",
    "            )\n",
    "            \n",
    "            if not all_source_datasets or cc_test_loader is None:\n",
    "                print(f\"警告：无法为CC类别创建数据加载器\")\n",
    "                return None, None, None, categories\n",
    "            \n",
    "            # 获取CC测试建筑ID\n",
    "            cc_test_building = train_test_labels[target_category][\"test\"][0]\n",
    "            \n",
    "            # 创建一个简单的单建筑数据集作为训练集\n",
    "            class EmptyDataset(Dataset):\n",
    "                def __len__(self):\n",
    "                    return 10  # 小数据集\n",
    "                \n",
    "                def __getitem__(self, idx):\n",
    "                    # 创建一个兼容的数据项\n",
    "                    x = torch.zeros((1, sequence_length, input_dim))  # [1建筑, 序列长度, 特征维度]\n",
    "                    y = torch.zeros((1, forecast_horizon))  # [1建筑, 预测长度]\n",
    "                    category = target_category\n",
    "                    category_onehot = torch.zeros(len(categories))\n",
    "                    category_idx = categories.index(target_category)\n",
    "                    category_onehot[category_idx] = 1.0\n",
    "                    return x, y, category, category_onehot\n",
    "            \n",
    "            # 使用包装器确保数据格式一致\n",
    "            class SingleBuildingWrapper(Dataset):\n",
    "                def __init__(self, dataset):\n",
    "                    self.dataset = dataset\n",
    "\n",
    "                def __len__(self):\n",
    "                    return len(self.dataset)\n",
    "\n",
    "                def __getitem__(self, idx):\n",
    "                    data = self.dataset[idx]\n",
    "                    if isinstance(data, tuple) and len(data) >= 2:\n",
    "                        inputs, targets = data[0], data[1]\n",
    "                        if inputs.shape[0] > 1:\n",
    "                            inputs = inputs[0:1]\n",
    "                            targets = targets[0:1]\n",
    "                        result = (inputs,) + (targets,) + data[2:]\n",
    "                        return result\n",
    "                    else:\n",
    "                        return data\n",
    "            \n",
    "            # 包装所有源域数据集\n",
    "            wrapped_source_datasets = [SingleBuildingWrapper(ds) for ds in all_source_datasets]\n",
    "            \n",
    "            # 创建空的训练集作为CC的训练数据\n",
    "            cc_train_dataset = EmptyDataset()\n",
    "            wrapped_cc_train = SingleBuildingWrapper(cc_train_dataset)\n",
    "            wrapped_cc_test = SingleBuildingWrapper(cc_test_loader.dataset)\n",
    "            \n",
    "            # 合并所有源域数据和CC的训练数据\n",
    "            class CombinedDataset(Dataset):\n",
    "                def __init__(self, datasets):\n",
    "                    self.datasets = datasets\n",
    "                    self.lengths = [len(ds) for ds in datasets]\n",
    "                    self.cumulative_lengths = [0]\n",
    "                    for length in self.lengths:\n",
    "                        self.cumulative_lengths.append(self.cumulative_lengths[-1] + length)\n",
    "\n",
    "                def __len__(self):\n",
    "                    return sum(self.lengths)\n",
    "\n",
    "                def __getitem__(self, idx):\n",
    "                    dataset_idx = bisect.bisect_right(self.cumulative_lengths, idx) - 1\n",
    "                    sample_idx = idx - self.cumulative_lengths[dataset_idx]\n",
    "                    return self.datasets[dataset_idx][sample_idx]\n",
    "            \n",
    "            # combined_train_loader = 所有其他类别的训练数据 + CC的训练时间段数据\n",
    "            combined_dataset = CombinedDataset(wrapped_source_datasets + [wrapped_cc_train])\n",
    "            combined_train_loader = DataLoader(\n",
    "                combined_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # target_test_loader_single = CC的测试数据\n",
    "            target_test_loader_single = DataLoader(\n",
    "                wrapped_cc_test,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # target_train_loader_single = CC的训练时间段数据\n",
    "            target_train_loader_single = DataLoader(\n",
    "                wrapped_cc_train,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            print(f\"CC类别数据加载器创建成功:\")\n",
    "            print(f\"  - combined_train_loader: {len(combined_dataset)} 样本 (包含所有其他类别 + CC训练时间段)\")\n",
    "            print(f\"  - target_test_loader: {len(wrapped_cc_test)} 样本\")\n",
    "            print(f\"  - target_train_loader: {len(wrapped_cc_train)} 样本\")\n",
    "            \n",
    "            return combined_train_loader, target_test_loader_single, target_train_loader_single, categories\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"创建数据加载器时出错: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, categories\n",
    "\n",
    "def adapt_to_target_domain_dann(source_model, source_loader, target_loader, epochs=20, lr=0.001, \n",
    "                              device='cuda', lambda_domain=0.4, early_stopping_patience=3):\n",
    "    \"\"\"\n",
    "    使用DANN方法将源域模型适应到目标域\n",
    "    \n",
    "    参数:\n",
    "    - source_model: 预训练的源域模型\n",
    "    - source_loader: 源域数据加载器\n",
    "    - target_loader: 目标域数据加载器\n",
    "    - epochs: 迁移训练轮数\n",
    "    - lr: 学习率\n",
    "    - device: 计算设备\n",
    "    - lambda_domain: 域对抗损失权重\n",
    "    - early_stopping_patience: 早停耐心值\n",
    "    \n",
    "    返回:\n",
    "    - model: 适应后的模型\n",
    "    - history: 训练历史\n",
    "    \"\"\"\n",
    "    # 配置日志\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler('dann_transfer_learning.log'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 忽略警告\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    \n",
    "    # 深拷贝源模型\n",
    "    model = copy.deepcopy(source_model).to(device)\n",
    "    \n",
    "    # 创建域分类器\n",
    "    domain_classifier = DomainClassifier(\n",
    "        feature_dim=model.hidden_dim,\n",
    "        hidden_dim=64,\n",
    "        dropout=0.3\n",
    "    ).to(device)\n",
    "    \n",
    "    # 设置优化器\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    optimizer_disc = optim.AdamW(domain_classifier.parameters(), lr=lr*0.5, weight_decay=0.02)\n",
    "    \n",
    "    # 设置学习率调度器\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=5, T_mult=2, eta_min=lr*0.1\n",
    "    )\n",
    "    \n",
    "    # 设置损失函数\n",
    "    huber_loss_fn = HuberLoss(delta=1.0)\n",
    "    domain_criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # 初始化训练记录\n",
    "    best_rmse = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    history = {'total_loss': [], 'task_loss': [], 'domain_loss': [], 'rmse': []}\n",
    "    \n",
    "    # 梯度裁剪阈值\n",
    "    max_grad_norm = 1.0\n",
    "    \n",
    "    logging.info(\"开始DANN域自适应迁移学习训练...\")\n",
    "    \n",
    "    # 主训练循环\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        domain_classifier.train()\n",
    "        \n",
    "        # 动态调整域对抗强度\n",
    "        p = float(epoch) / epochs\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1  # 从0逐渐增加到1\n",
    "        model.set_alpha(alpha * lambda_domain)\n",
    "        \n",
    "        # 初始化统计变量\n",
    "        epoch_stats = {'total_loss': 0, 'task_loss': 0, 'domain_loss': 0}\n",
    "        \n",
    "        # 批次训练循环\n",
    "        n_batches = min(len(source_loader), len(target_loader))\n",
    "        progress_bar = tqdm(range(n_batches), desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        for batch_idx in progress_bar:\n",
    "            try:\n",
    "                # 获取源域和目标域的一个批次数据\n",
    "                source_batch = next(iter(source_loader))\n",
    "                target_batch = next(iter(target_loader))\n",
    "                \n",
    "                # 解析数据并移动到计算设备\n",
    "                source_inputs, source_targets, _, source_category = [\n",
    "                    x.float().to(device) if torch.is_tensor(x) else x for x in source_batch\n",
    "                ]\n",
    "                target_inputs, target_targets, _, target_category = [\n",
    "                    x.float().to(device) if torch.is_tensor(x) else x for x in target_batch\n",
    "                ]\n",
    "                \n",
    "                # 1. 特征提取\n",
    "                source_features = model.get_features(source_inputs)\n",
    "                target_features = model.get_features(target_inputs)\n",
    "                \n",
    "                # 2. 域对抗训练\n",
    "                # 准备域标签（源域=0，目标域=1）\n",
    "                batch_size = source_features.size(0)\n",
    "                source_domain_labels = torch.zeros(batch_size, 1).to(device)\n",
    "                target_domain_labels = torch.ones(batch_size, 1).to(device)\n",
    "                \n",
    "                # 连接特征和标签\n",
    "                features = torch.cat([source_features, target_features], dim=0)\n",
    "                domain_labels = torch.cat([source_domain_labels, target_domain_labels], dim=0)\n",
    "                \n",
    "                # 域分类器预测\n",
    "                domain_preds = domain_classifier(model.grl(features))\n",
    "                domain_loss = domain_criterion(domain_preds, domain_labels)\n",
    "                \n",
    "                # 3. 任务预测\n",
    "                source_predictions = model(source_inputs, source_category)\n",
    "                target_predictions = model(target_inputs, target_category)\n",
    "                \n",
    "                # 4. 计算任务损失\n",
    "                source_task_loss = huber_loss_fn(source_predictions, source_targets)\n",
    "                target_task_loss = huber_loss_fn(target_predictions, target_targets)\n",
    "                \n",
    "                # 5. 动态平衡源域和目标域任务权重\n",
    "                src_weight = max(0.2, 1.0 - epoch/epochs)    # 源域权重从1线性衰减到0.2\n",
    "                tgt_weight = min(5.0, 1.0 + epoch*4/epochs)   # 目标域权重从1线性增加到5\n",
    "                \n",
    "                # 6. 计算总损失\n",
    "                task_loss = source_task_loss * src_weight + target_task_loss * tgt_weight\n",
    "                total_loss = task_loss + domain_loss * model.alpha\n",
    "                \n",
    "                # 7. 反向传播与优化\n",
    "                optimizer.zero_grad()\n",
    "                optimizer_disc.zero_grad()\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "                torch.nn.utils.clip_grad_norm_(domain_classifier.parameters(), max_grad_norm)\n",
    "                \n",
    "                # 更新参数\n",
    "                optimizer.step()\n",
    "                optimizer_disc.step()\n",
    "                \n",
    "                # 统计损失\n",
    "                epoch_stats['total_loss'] += total_loss.item()\n",
    "                epoch_stats['task_loss'] += task_loss.item()\n",
    "                epoch_stats['domain_loss'] += domain_loss.item()\n",
    "                \n",
    "                # 更新进度条\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{total_loss.item():.4f}\",\n",
    "                    'task': f\"{task_loss.item():.4f}\",\n",
    "                    'domain': f\"{domain_loss.item():.4f}\",\n",
    "                    'alpha': f\"{model.alpha:.4f}\"\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.warning(f\"批次处理出错: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 计算平均损失\n",
    "        avg_total_loss = epoch_stats['total_loss'] / n_batches\n",
    "        avg_task_loss = epoch_stats['task_loss'] / n_batches\n",
    "        avg_domain_loss = epoch_stats['domain_loss'] / n_batches\n",
    "        \n",
    "        # 记录训练历史\n",
    "        history['total_loss'].append(avg_total_loss)\n",
    "        history['task_loss'].append(avg_task_loss)\n",
    "        history['domain_loss'].append(avg_domain_loss)\n",
    "        \n",
    "        # 评估模型\n",
    "        current_rmse = evaluate_dann_on_target(model, target_loader, device)\n",
    "        history['rmse'].append(current_rmse)\n",
    "        \n",
    "        logging.info(\n",
    "            f\"Epoch {epoch+1}/{epochs} - \"\n",
    "            f\"Loss: {avg_total_loss:.4f}, \"\n",
    "            f\"Task: {avg_task_loss:.4f}, \"\n",
    "            f\"Domain: {avg_domain_loss:.4f}, \"\n",
    "            f\"RMSE: {current_rmse:.4f}, \"\n",
    "            f\"Alpha: {model.alpha:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # 早停检查\n",
    "        if current_rmse < best_rmse:\n",
    "            best_rmse = current_rmse\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "            logging.info(f\"发现新的最佳RMSE: {best_rmse:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            logging.info(f\"未改进RMSE，耐心值: {patience_counter}/{early_stopping_patience}\")\n",
    "            \n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                logging.info(f\"触发早停，在epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # 恢复最佳模型\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        logging.info(f\"已恢复最佳模型\")\n",
    "    \n",
    "    # 保存模型\n",
    "    try:\n",
    "        checkpoint_path = f'models/dann_adapted_model.pth'\n",
    "        torch.save({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'domain_classifier': domain_classifier.state_dict(),\n",
    "            'history': history,\n",
    "            'best_rmse': best_rmse\n",
    "        }, checkpoint_path)\n",
    "        logging.info(f\"模型已保存到 {checkpoint_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"保存模型失败: {str(e)}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_dann_on_target(model, target_loader, device):\n",
    "    \"\"\"\n",
    "    在目标域数据上评估DANN模型的RMSE\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, _, category in target_loader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            category = category.float().to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            predictions = model(inputs, category)\n",
    "            \n",
    "            # 收集预测和目标\n",
    "            all_preds.append(predictions.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "    \n",
    "    # 合并所有批次\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    # 计算RMSE\n",
    "    mse = torch.mean((all_preds - all_targets) ** 2)\n",
    "    rmse = torch.sqrt(mse).item()\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# ========================= 主程序 =========================\n",
    "\n",
    "# 模型参数设置\n",
    "batch_size = 32\n",
    "sequence_length = 24\n",
    "forecast_horizon = 24\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "transfer_epochs = 15\n",
    "input_dim = 6\n",
    "\n",
    "# 定义域索引映射\n",
    "DOMAIN_MAPPING = {\n",
    "    \"DO\": 1,\n",
    "    \"HO\": 2,\n",
    "    \"LI\": 3,\n",
    "    \"OF\": 4,\n",
    "    \"UL\": 5,\n",
    "    \"CC\": None\n",
    "}\n",
    "\n",
    "# 数据缺失场景\n",
    "data_shortage_scenarios = ['mild', 'heavy', 'extreme']\n",
    "with open('train_test_labels.json', 'r') as f:\n",
    "    train_test_labels = json.load(f)\n",
    "# 加载数据\n",
    "print(\"加载所有类别的训练数据...\")\n",
    "train_loader, test_loader, categories = create_all_dataloaders(\n",
    "    batch_size=batch_size, \n",
    "    sequence_length=sequence_length, \n",
    "    forecast_horizon=forecast_horizon\n",
    ")\n",
    "\n",
    "# 获取数据维度信息\n",
    "for inputs, targets, category, category_onehot in train_loader:\n",
    "    print(f\"输入形状: {inputs.shape}, 目标形状: {targets.shape}, 类别形状: {category_onehot.shape}\")\n",
    "    input_dim = inputs.shape[-1]\n",
    "    num_buildings = inputs.shape[1]\n",
    "    category_dim = category_onehot.shape[-1]\n",
    "    break\n",
    "\n",
    "# 创建DANN模型\n",
    "print(\"创建DANN模型...\")\n",
    "source_model = DANN(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    category_dim=category_dim,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    num_buildings=num_buildings,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    alpha=0.0  # 源域训练时不使用域对抗\n",
    ")\n",
    "\n",
    "# 训练源域模型\n",
    "print(\"训练源域DANN模型...\")\n",
    "# 这里可以使用您原有的训练函数，只需将模型替换为DANN模型\n",
    "\n",
    "# 迁移学习循环\n",
    "transfer_results = {}\n",
    "source_domain_idx = 0\n",
    "\n",
    "for target_category in categories:\n",
    "    transfer_results[target_category] = {}\n",
    "    target_domain_idx = DOMAIN_MAPPING[target_category]\n",
    "    \n",
    "    for data_shortage in data_shortage_scenarios:\n",
    "        print(f\"\\n🚀 [Transfer Learning] Source(ALL) ➜ Target({target_category}), Shortage: {data_shortage}\")\n",
    "        \n",
    "        try:\n",
    "            # 初始化结果字典\n",
    "            transfer_results[target_category][data_shortage] = {}\n",
    "            \n",
    "            # 加载数据\n",
    "            combined_train_loader, target_test_loader, target_train_loader, _ = create_combined_dataloaders(\n",
    "                source_category=target_category,\n",
    "                target_category=target_category,\n",
    "                data_shortage=data_shortage,\n",
    "                batch_size=batch_size,\n",
    "                sequence_length=sequence_length,\n",
    "                forecast_horizon=forecast_horizon\n",
    "            )\n",
    "            \n",
    "            # 检查数据加载器\n",
    "            if combined_train_loader is None or target_test_loader is None:\n",
    "                print(f\"⚠️ 无法为 {target_category}/{data_shortage} 创建数据加载器，跳过\")\n",
    "                continue\n",
    "\n",
    "            # 使用DANN进行迁移学习\n",
    "            print(f\"🔄 使用DANN进行迁移学习 for category {target_category}...\")\n",
    "            adapted_model, transfer_history = adapt_to_target_domain_dann(\n",
    "                source_model=source_model,\n",
    "                source_loader=combined_train_loader,\n",
    "                target_loader=target_test_loader,\n",
    "                epochs=transfer_epochs,\n",
    "                lr=learning_rate / 2,\n",
    "                device=device,\n",
    "                lambda_domain=0.4,\n",
    "                early_stopping_patience=3\n",
    "            )\n",
    "            \n",
    "            # 评估DANN模型（适应evaluate_model的修改）\n",
    "            print(f\"📊 评估DANN模型 for category {target_category}...\")\n",
    "            dann_metrics = evaluate_model(\n",
    "                model=adapted_model,\n",
    "                test_loader=target_test_loader,\n",
    "                model_name=f\"DANN_TL_ALL_to_{target_category}_{data_shortage}\",\n",
    "                baseline_model=None,  # 保持基线模型参数\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # 保存DANN模型结果（更新保存逻辑）\n",
    "            transfer_results[target_category][data_shortage]['dann'] = {\n",
    "                'metrics': dann_metrics,\n",
    "                'model_type': \"dann\",\n",
    "                # 新增：提取并保存特定指标\n",
    "                'rmsd': dann_metrics.get('RMSD', 'N/A'),\n",
    "                'cv_rmse': dann_metrics.get('CV-RMSE', 'N/A'),\n",
    "                'sd_real': dann_metrics.get('SD_real', 'N/A'),\n",
    "                'sd_pred': dann_metrics.get('SD_pred', 'N/A'),\n",
    "                'cc': dann_metrics.get('CC', 'N/A'),\n",
    "                # 迁移学习增益指标\n",
    "                'transfer_gain': dann_metrics.get('transfer_gain', 'N/A'),\n",
    "                'is_negative_transfer': dann_metrics.get('is_negative_transfer', 'N/A')\n",
    "            }\n",
    "            \n",
    "            # 打印指标对比表（更新表格生成逻辑）\n",
    "            print(\"\\n📊 基线模型 vs DANN模型 指标对比:\")\n",
    "            print_metrics_table([\n",
    "                {\n",
    "                    'name': 'Baseline',\n",
    "                    'metrics': calculate_metrics\n",
    "                },\n",
    "                {\n",
    "                    'name': 'DANN',\n",
    "                    'metrics': dann_metrics\n",
    "                }\n",
    "            ])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {target_category}/{data_shortage} transfer failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "print(\"\\n✅ 所有迁移学习实验完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9cb4b-8dc7-4036-beef-e5ecf7e6c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 保存结果 =========================\n",
    "\n",
    "# 保存迁移学习结果到JSON文件\n",
    "try:\n",
    "    # 将结果转换为可序列化格式\n",
    "    def convert_to_serializable(obj):\n",
    "        \"\"\"将对象转换为JSON可序列化的格式\"\"\"\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            # 将张量转换为Python原生类型\n",
    "            obj = obj.detach().cpu().numpy()\n",
    "            if obj.size == 1:\n",
    "                return float(obj.item())  # 单个值转为float\n",
    "            return obj.tolist()  # 数组转为列表\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            # 将NumPy数组转换为列表\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, (np.float32, np.float64, np.int32, np.int64)):\n",
    "            # 将NumPy标量转换为Python标量\n",
    "            return float(obj) if np.issubdtype(obj.dtype, np.floating) else int(obj)\n",
    "        elif isinstance(obj, dict):\n",
    "            # 递归处理字典\n",
    "            return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            # 递归处理列表\n",
    "            return [convert_to_serializable(item) for item in obj]\n",
    "        elif isinstance(obj, (float, int, str, bool, type(None))):\n",
    "            # 这些类型已经是JSON可序列化的\n",
    "            return obj\n",
    "        else:\n",
    "            # 其他类型，尝试转换为字符串\n",
    "            try:\n",
    "                return str(obj)\n",
    "            except:\n",
    "                return \"Non-serializable object\"\n",
    "    \n",
    "    # 转换结果为可序列化格式\n",
    "    serializable_results = convert_to_serializable(transfer_results)\n",
    "    \n",
    "    # 保存到JSON文件\n",
    "    results_path = 'results/dann_transfer_results.json'\n",
    "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(serializable_results, f, indent=4)\n",
    "    \n",
    "    print(f\"✅ 迁移学习结果已保存到 {results_path}\")\n",
    "    \n",
    "    # 保存结果到CSV文件\n",
    "    # 准备CSV数据（新增SD、CV-RMSE等指标）\n",
    "    csv_data = []\n",
    "    csv_headers = [\n",
    "        'Category', 'Data_Shortage', 'Model_Type', \n",
    "        'RMSD', 'MAPE', 'R2', 'CV-RMSE', 'SD_real', 'SD_pred', 'CC', \n",
    "        'PIR', 'PICP', 'NMPIW', 'Calibration_Error', 'UQS', 'Avg_Uncertainty',\n",
    "        'A_distance', 'Feature_Alignment', 'MMD', \n",
    "        'Is_Negative_Transfer', 'Transfer_Gain', 'Sample_Efficiency'\n",
    "    ]\n",
    "    \n",
    "    for category, category_results in transfer_results.items():\n",
    "        for shortage, shortage_results in category_results.items():\n",
    "            for model_type, model_data in shortage_results.items():\n",
    "                if 'metrics' in model_data:\n",
    "                    metrics = model_data['metrics']\n",
    "                    row = {\n",
    "                        'Category': category,\n",
    "                        'Data_Shortage': shortage,\n",
    "                        'Model_Type': model_type,\n",
    "                        'RMSD': metrics.get('RMSD', 'N/A'),\n",
    "                        'MAPE': metrics.get('MAPE', 'N/A'),\n",
    "                        'R2': metrics.get('R2', 'N/A'),\n",
    "                        'CV-RMSE': metrics.get('CV-RMSE', 'N/A'),\n",
    "                        'SD_real': metrics.get('SD_real', 'N/A'),\n",
    "                        'SD_pred': metrics.get('SD_pred', 'N/A'),\n",
    "                        'CC': metrics.get('CC', 'N/A'),\n",
    "                        'PIR': metrics.get('PIR', 'N/A'),\n",
    "                        'PICP': metrics.get('PICP', 'N/A'),\n",
    "                        'NMPIW': metrics.get('NMPIW', 'N/A'),\n",
    "                        'Calibration_Error': metrics.get('calibration_error', 'N/A'),\n",
    "                        'UQS': metrics.get('UQS', 'N/A'),\n",
    "                        'Avg_Uncertainty': metrics.get('avg_uncertainty', 'N/A'),\n",
    "                        'A_distance': metrics.get('a_distance', 'N/A'),\n",
    "                        'Feature_Alignment': metrics.get('feature_alignment', 'N/A'),\n",
    "                        'MMD': metrics.get('mmd', 'N/A'),\n",
    "                        'Is_Negative_Transfer': metrics.get('is_negative_transfer', 'N/A'),\n",
    "                        'Transfer_Gain': metrics.get('transfer_gain', 'N/A'),\n",
    "                        'Sample_Efficiency': metrics.get('sample_efficiency', 'N/A')\n",
    "                    }\n",
    "                    csv_data.append(row)\n",
    "    \n",
    "    # 创建DataFrame并保存为CSV\n",
    "    csv_path = 'results/dann_transfer_results.csv'\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"✅ 迁移学习结果已保存到CSV文件: {csv_path}\")\n",
    "    \n",
    "    # 为每个类别创建单独的CSV文件\n",
    "    for category in transfer_results.keys():\n",
    "        category_data = [row for row in csv_data if row['Category'] == category]\n",
    "        if category_data:\n",
    "            category_csv_path = f'results/dann_transfer_results_{category}.csv'\n",
    "            pd.DataFrame(category_data).to_csv(category_csv_path, index=False)\n",
    "            print(f\"✅ 类别 {category} 的结果已保存到: {category_csv_path}\")\n",
    "    \n",
    "    # 创建性能对比汇总CSV（新增SD、CV-RMSE对比）\n",
    "    summary_data = []\n",
    "    for shortage in data_shortage_scenarios:\n",
    "        for category in transfer_results.keys():\n",
    "            if shortage in transfer_results[category]:\n",
    "                baseline_metrics = {}\n",
    "                dann_metrics = {}\n",
    "                \n",
    "                if ('baseline' in transfer_results[category][shortage] and \n",
    "                    'metrics' in transfer_results[category][shortage]['baseline']):\n",
    "                    baseline_metrics = transfer_results[category][shortage]['baseline']['metrics']\n",
    "                \n",
    "                if ('dann' in transfer_results[category][shortage] and \n",
    "                    'metrics' in transfer_results[category][shortage]['dann']):\n",
    "                    dann_metrics = transfer_results[category][shortage]['dann']['metrics']\n",
    "                \n",
    "                # 计算各指标改进百分比\n",
    "                def calculate_improvement(baseline, dann):\n",
    "                    if baseline != 'N/A' and dann != 'N/A' and baseline != 0:\n",
    "                        return (baseline - dann) / baseline * 100\n",
    "                    return 'N/A'\n",
    "                \n",
    "                # 提取关键指标\n",
    "                baseline_rmsd = baseline_metrics.get('RMSD', 'N/A')\n",
    "                dann_rmsd = dann_metrics.get('RMSD', 'N/A')\n",
    "                rmsd_improvement = calculate_improvement(baseline_rmsd, dann_rmsd)\n",
    "                \n",
    "                baseline_cv_rmse = baseline_metrics.get('CV-RMSE', 'N/A')\n",
    "                dann_cv_rmse = dann_metrics.get('CV-RMSE', 'N/A')\n",
    "                cv_rmse_improvement = calculate_improvement(baseline_cv_rmse, dann_cv_rmse)\n",
    "                \n",
    "                baseline_sd = baseline_metrics.get('SD_pred', 'N/A')\n",
    "                dann_sd = dann_metrics.get('SD_pred', 'N/A')\n",
    "                sd_improvement = calculate_improvement(baseline_sd, dann_sd) if baseline_sd != 'N/A' and dann_sd != 'N/A' else 'N/A'\n",
    "                \n",
    "                baseline_cc = baseline_metrics.get('CC', 'N/A')\n",
    "                dann_cc = dann_metrics.get('CC', 'N/A')\n",
    "                cc_improvement = calculate_improvement(baseline_cc, dann_cc) if baseline_cc != 'N/A' and dann_cc != 'N/A' else 'N/A'\n",
    "                \n",
    "                summary_data.append({\n",
    "                    'Category': category,\n",
    "                    'Data_Shortage': shortage,\n",
    "                    'Baseline_RMSD': baseline_rmsd,\n",
    "                    'DANN_RMSD': dann_rmsd,\n",
    "                    'RMSD_Improvement_Percent': rmsd_improvement,\n",
    "                    'Baseline_CV-RMSE': baseline_cv_rmse,\n",
    "                    'DANN_CV-RMSE': dann_cv_rmse,\n",
    "                    'CV-RMSE_Improvement_Percent': cv_rmse_improvement,\n",
    "                    'Baseline_SD': baseline_sd,\n",
    "                    'DANN_SD': dann_sd,\n",
    "                    'SD_Improvement_Percent': sd_improvement,\n",
    "                    'Baseline_CC': baseline_cc,\n",
    "                    'DANN_CC': dann_cc,\n",
    "                    'CC_Improvement_Percent': cc_improvement\n",
    "                })\n",
    "    \n",
    "    # 保存性能对比汇总\n",
    "    summary_csv_path = 'results/dann_performance_summary.csv'\n",
    "    pd.DataFrame(summary_data).to_csv(summary_csv_path, index=False)\n",
    "    print(f\"✅ 性能对比汇总已保存到: {summary_csv_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 保存结果失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n🎉 DANN迁移学习实验全部完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092c7fc-0e50-4441-83a8-9a458405d2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407561e-d9c5-4f86-bf6f-57aa92d407a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad75de-c59c-45bd-98ce-c918b016c61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
